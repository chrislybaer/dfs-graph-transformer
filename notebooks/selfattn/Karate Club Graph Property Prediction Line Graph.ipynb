{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f001349",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96dfaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "2022-01-31 13:51:27.042563: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2022-01-31 13:51:27.042587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from ml_collections import ConfigDict \n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import networkx as nx\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import dfs_code \n",
    "from dfs_transformer import collate_downstream, DFSCodeSeq2SeqFC, Trainer\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed17efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file = \"/mnt/ssd/datasets/graphs/reddit_threads/reddit_edges.json\"\n",
    "label_file = \"/mnt/ssd/datasets/graphs/reddit_threads/reddit_target.csv\"\n",
    "batch_size = 250\n",
    "rep = 1\n",
    "max_edges = 150\n",
    "n_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fb23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graph_file, 'r') as f:\n",
    "    graph_dict = json.load(f)\n",
    "label_df = pd.read_csv(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fabc13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   1       1\n",
       "2   2       0\n",
       "3   3       1\n",
       "4   4       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece9b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n_edges = [len(graph) for graph in graph_dict.values()]\n",
    "plt.hist(n_edges, bins='rice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdf7a7",
   "metadata": {},
   "source": [
    "connected =  []\n",
    "for graph in tqdm.tqdm(graph_dict.values()):\n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from(graph)\n",
    "    lg = nx.generators.line.line_graph(g)\n",
    "    connected += [nx.is_connected(lg)]\n",
    "connected = np.asarray(connected)\n",
    "print(connected.sum()/len(connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af92f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph2labelledgraph(graph, use_dummy=False):\n",
    "    graph = deepcopy(graph)\n",
    "    \n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from(graph)\n",
    "    lg = nx.generators.line.line_graph(g)\n",
    "    node_ids = {node:idx for idx, node in enumerate(lg.nodes)}\n",
    "    edges = []\n",
    "    for edge in lg.edges:\n",
    "        edges += [[node_ids[edge[0]], node_ids[edge[1]]]]\n",
    "        edges += [[node_ids[edge[1]], node_ids[edge[0]]]]\n",
    "    \n",
    "    edgeindex = np.asarray(edges).T\n",
    "    node_ids = np.arange(len(node_ids))\n",
    "    edge_labels = [0]*edgeindex.shape[1]\n",
    "    \n",
    "    node_labels = []\n",
    "    for idx in node_ids:\n",
    "        node_labels += [(edgeindex[0] == idx).sum()]\n",
    "    return edgeindex, node_labels, edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c299c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_dict['0']\n",
    "code, index = dfs_code.rnd_dfs_code_from_edgeindex(*graph2labelledgraph(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865cd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "code2, index2 = dfs_code.rnd_dfs_code_from_edgeindex(*graph2labelledgraph(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63715928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KarateClubDataset(Dataset):\n",
    "    def __init__(self, graph_file, label_file, max_n = None, max_edges=50):\n",
    "        self.graph_file = graph_file\n",
    "        self.label_file = label_file\n",
    "        with open(graph_file, 'r') as f:\n",
    "            self.graph_dict = json.load(f)\n",
    "        self.label_df = pd.read_csv(label_file)\n",
    "        self.data = []\n",
    "        self.maxn = max_n\n",
    "        self.max_edges = max_edges\n",
    "        self.preprocess()\n",
    "    \n",
    "    def preprocess(self):\n",
    "        maxn = self.maxn\n",
    "        maxdegree = 0\n",
    "        edgeindex_list = []\n",
    "        vlabels_list = []\n",
    "        elabels_list = []\n",
    "        label_list = []\n",
    "        for idx, (graph, label) in tqdm.tqdm(enumerate(zip(self.graph_dict.values(), self.label_df['target']))):  \n",
    "            edgeindex, vlabels, elabels = graph2labelledgraph(graph)\n",
    "            if len(elabels)//2 > self.max_edges:\n",
    "                continue\n",
    "            maxdegree = max(maxdegree, max(vlabels))\n",
    "            edgeindex_list += [edgeindex]\n",
    "            vlabels_list += [vlabels]\n",
    "            elabels_list += [elabels]\n",
    "            label_list +=[self.label_df['target'][idx]]\n",
    "            if maxn is not None:\n",
    "                if idx >= maxn:\n",
    "                    break\n",
    "        self.maxdegree = maxdegree\n",
    "        \n",
    "        for idx, (edgeindex, vlabels, elabels, label) in tqdm.tqdm(enumerate(zip(edgeindex_list,\n",
    "                                                                                vlabels_list,\n",
    "                                                                                elabels_list, \n",
    "                                                                                label_list))):  \n",
    "            node_features = F.one_hot(torch.tensor(vlabels), num_classes=maxdegree+1).float()\n",
    "            edge_features = F.one_hot(torch.tensor(elabels), num_classes=2).float()\n",
    "            #code, index = dfs_code.rnd_dfs_code_from_edgeindex(edgeindex, vlabels, elabels)\n",
    "            self.data += [ConfigDict({\"node_labels\":torch.tensor(vlabels),\n",
    "                                    \"edge_labels\":torch.tensor(elabels),\n",
    "                                    \"edge_index\":torch.tensor(edgeindex, dtype=torch.long),\n",
    "                                    #\"min_dfs_code\":torch.tensor(code),\n",
    "                                    #\"min_dfs_index\":torch.tensor(index, dtype=torch.long),\n",
    "                                    \"node_features\":node_features,\n",
    "                                    \"edge_features\":edge_features,\n",
    "                                    \"y\": torch.tensor(label, dtype=torch.float32),\n",
    "                                    \"idx\":idx})]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e0af6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [00:08, 1138.44it/s]\n",
      "7063it [00:00, 8047.12it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = KarateClubDataset(graph_file, label_file, max_n=n_samples, max_edges=max_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d10d026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3b997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dataset)\n",
    "n_train = int(0.8*n)\n",
    "n_valid = 0\n",
    "n_test = n - n_train - n_valid\n",
    "\n",
    "perm = np.random.permutation(len(dataset))\n",
    "train_idx = torch.tensor(perm[:n_train], dtype=torch.long)\n",
    "valid_idx = torch.tensor(perm[n_train:n_train+n_valid].tolist(), dtype=torch.long)\n",
    "test_idx = torch.tensor(perm[n_train+n_valid:].tolist(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59ab26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d88968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist, use_min=False, rep=rep):\n",
    "    dfs_codes = defaultdict(list)\n",
    "    node_batch = [] \n",
    "    edge_batch = []\n",
    "    y_batch = []\n",
    "    rnd_code_batch = []\n",
    "    \n",
    "    for d in dlist:\n",
    "        for r in range(rep):\n",
    "            edge_features = d.edge_features.clone()\n",
    "            if use_min:\n",
    "                code = d.min_dfs_code.clone()\n",
    "                index = d.min_dfs_index.clone()\n",
    "            else:\n",
    "                code, index = dfs_code.rnd_dfs_code_from_edgeindex(d.edge_index.numpy(), \n",
    "                                                                   d.node_labels.numpy().tolist(), \n",
    "                                                                   d.edge_labels.numpy().tolist())\n",
    "\n",
    "                code = torch.tensor(np.asarray(code), dtype=torch.long)\n",
    "                index = torch.tensor(np.asarray(index), dtype=torch.long)\n",
    "\n",
    "\n",
    "            rnd_code_batch += [code]\n",
    "            node_batch += [d.node_features.clone()]\n",
    "            edge_batch += [edge_features]\n",
    "            y_batch += [d.y.unsqueeze(0).clone()]\n",
    "\n",
    "    y = torch.cat(y_batch).unsqueeze(1)\n",
    "\n",
    "    \n",
    "    for inp, nfeats, efeats in zip(rnd_code_batch, node_batch, edge_batch):\n",
    "        dfs_codes['dfs_from'] += [inp[:, 0]]\n",
    "        dfs_codes['dfs_to'] += [inp[:, 1]]\n",
    "        atm_from_feats = nfeats[inp[:, -3]]\n",
    "        atm_to_feats = nfeats[inp[:, -1]]\n",
    "        bnd_feats = efeats[inp[:, -2]]\n",
    "        dfs_codes['atm_from'] += [atm_from_feats]\n",
    "        dfs_codes['atm_to'] += [atm_to_feats]\n",
    "        dfs_codes['bnd'] += [bnd_feats]\n",
    "\n",
    "    dfs_codes = {key: nn.utils.rnn.pad_sequence(values, padding_value=-1000).clone()\n",
    "                 for key, values in dfs_codes.items()}\n",
    "    return dfs_codes, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2267a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(train_idx), \n",
    "                         batch_size=batch_size, collate_fn=collate_fn, num_workers=8)\n",
    "validloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(valid_idx), \n",
    "                         batch_size=batch_size, collate_fn=collate_fn, num_workers=8)\n",
    "testloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(test_idx), \n",
    "                        batch_size=batch_size, collate_fn=collate_fn, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4bd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPlusHead(nn.Module):\n",
    "    def __init__(self, encoder, n_classes, fingerprint='cls'):\n",
    "        super(TransformerPlusHead, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        #self.head = nn.Linear(encoder.get_n_encoding(fingerprint), n_classes)\n",
    "        self.head = nn.Sequential(nn.Linear(encoder.get_n_encoding(fingerprint), 128),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Linear(128, 128),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Linear(128, n_classes))\n",
    "        self.fingerprint = fingerprint\n",
    "    \n",
    "    def forward(self, dfs_code):\n",
    "        #with torch.no_grad():\n",
    "        features = self.encoder.encode(dfs_code, method=self.fingerprint)\n",
    "        output = self.head(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1b83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../config/selfattn/model/bert.yaml\") as file:\n",
    "    m = ConfigDict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac9b5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"n_atoms\"] = int(dataset.maxdegree)+1\n",
    "m[\"n_node_features\"] = int(dataset.maxdegree)+1\n",
    "m[\"n_bonds\"] = 2\n",
    "m[\"n_edge_features\"] = 2\n",
    "m[\"nlayers\"] = 6\n",
    "m[\"emb_dim\"] = 100\n",
    "m[\"nhead\"] = 10\n",
    "m[\"max_edges\"] = max_edges\n",
    "m[\"max_nodes\"] = max_edges\n",
    "m[\"dim_feedforward\"] = 4*m[\"emb_dim\"]\n",
    "m[\"batch_size\"] = batch_size\n",
    "m[\"rep\"] = rep\n",
    "m[\"max_edges\"] = max_edges\n",
    "m[\"n_samples\"] = n_samples\n",
    "m[\"encoder_class\"] = \"DFSCodeEncoder\"\n",
    "m[\"training\"] = {}\n",
    "encoder = DFSCodeSeq2SeqFC(**m)\n",
    "model = TransformerPlusHead(encoder, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc05e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y, ce=ce):\n",
    "    return ce(pred, y.float())\n",
    "\n",
    "def auc(pred, y):\n",
    "    return roc_auc_score(y.detach().cpu().numpy(), pred[:, 0].detach().cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c53e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-01-31 13:51:50.468616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2022-01-31 13:51:50.468636: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">linegraph</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dfstransformer/karateclub-reddit-50\" target=\"_blank\">https://wandb.ai/dfstransformer/karateclub-reddit-50</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dfstransformer/karateclub-reddit-50/runs/p5asynyb\" target=\"_blank\">https://wandb.ai/dfstransformer/karateclub-reddit-50/runs/p5asynyb</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer-feature-dataloader/notebooks/selfattn/wandb/run-20220131_135149-p5asynyb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(mode=\"online\", project=\"karateclub-reddit-50\", entity=\"dfstransformer\", \n",
    "                 config=m.to_dict(), job_type=\"evaluation\", name=\"linegraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ca24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainloader, loss, metrics={'auc': auc}, lr=0.000015, validloader=testloader, \n",
    "                  es_period=10*n_train//batch_size, lr_adjustment_period=10*n_train//batch_size//4, wandb_run=run,\n",
    "                  clip_gradient_norm=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5796bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss 0.669907 0.6938: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:14<00:00,  1.63it/s]\n",
      "Epoch 2: loss 0.615654 0.7601: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:13<00:00,  1.68it/s]\n",
      "Epoch 3: loss 0.568296 0.7849: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:13<00:00,  1.67it/s]\n",
      "Epoch 4: loss 0.547427 0.7993: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:13<00:00,  1.67it/s]\n",
      "Epoch 5: loss 0.538517 0.8037: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:13<00:00,  1.66it/s]\n",
      "Epoch 6: loss 0.538031 0.8017: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:13<00:00,  1.65it/s]\n",
      "Epoch 7: loss 0.532166 0.8030: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:14<00:00,  1.60it/s]\n",
      "Epoch 8: loss 0.536012 0.7993:  43%|██████████████████████████████████████████████████████████████▏                                                                                | 10/23 [00:07<00:09,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c4d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3127f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

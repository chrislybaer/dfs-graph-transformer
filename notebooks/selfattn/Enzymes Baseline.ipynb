{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "2021-10-05 15:14:17.330244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-10-05 15:14:17.330285: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the Graphein submodule graphein.protein.features.sequence.embeddings, you need to install biovec.\n",
      "\n",
      "To do so, use the following command:\n",
      "\n",
      "    pip install biovec\n",
      "To use the Graphein submodule graphein.protein.visualisation, you need to install pytorch3d.\n",
      "\n",
      "pytorch3d cannot be installed via pip\n",
      "To use the Graphein submodule graphein.protein.meshes, you need to install pytorch3d.\n",
      "\n",
      "pytorch3d cannot be installed via pip\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers\n",
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import yaml\n",
    "import functools\n",
    "from ml_collections import ConfigDict\n",
    "sys.path = ['../../src'] + sys.path\n",
    "from dfs_transformer import collate_dgl, Gilmer, Trainer, to_cuda, Enzymes\n",
    "from graphein.protein.resi_atoms import RESI_THREE_TO_1, AMINO_ACIDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7962f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = functools.partial(collate_dgl, node_feats=\"node_features\", edge_feats=\"edge_features\", target=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9838e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConfigDict()\n",
    "t = ConfigDict()\n",
    "d = ConfigDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dec3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"class\"] = \"Gilmer\"\n",
    "m[\"n_tasks\"] = 1\n",
    "m[\"node_out_feats\"] = 64\n",
    "m[\"edge_hidden_feats\"] = 128\n",
    "m[\"num_step_message_passing\"] = 3\n",
    "m[\"num_step_set2set\"] = 6\n",
    "m[\"num_layer_set2set\"] = 3\n",
    "m[\"mode\"] = 'classification'\n",
    "m[\"number_atom_features\"] = 26\n",
    "m[\"number_bond_features\"] = 8\n",
    "m[\"n_classes\"] = 384\n",
    "m[\"nfeat_name\"] = 'x'\n",
    "m[\"efeat_name\"] = 'edge_attr'\n",
    "\n",
    "\n",
    "t[\"batch_size\"] = 50\n",
    "t[\"gpu_id\"] = None\n",
    "t[\"load_last\"] = False\n",
    "t[\"fingerprint\"] = \"cls\"\n",
    "t[\"accumulate_grads\"] = 2\n",
    "t[\"alpha\"] = 0.0\n",
    "t[\"clip_gradient\"] = 0.5\n",
    "t[\"decay_factor\"] = 0.8\n",
    "t[\"es_improvement\"] = 0.0\n",
    "t[\"es_path\"] = None\n",
    "t[\"es_patience\"] = 30\n",
    "t[\"es_period\"] = 203\n",
    "t[\"lr\"] = 0.003\n",
    "t[\"lr_patience\"] = 3\n",
    "t[\"lr_adjustment_period\"] = 203\n",
    "t[\"wdecay_encoder\"] = 0.0\n",
    "t[\"n_epochs\"] = 1000\n",
    "t[\"seed\"] = 123\n",
    "t[\"num_workers\"] = 8\n",
    "\n",
    "d[\"n_classes\"] = 384\n",
    "d[\"path\"] = \"/mnt/ssd/datasets/enzyme/graphein_basic_n1000_m500.pkl\"\n",
    "d[\"n_edge_types\"] = 8\n",
    "d[\"n_node_types\"] = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69ff7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"online\"\n",
    "name = \"gilmer\"\n",
    "project = \"enzymes-n200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8e1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Enzymes(path=d.path, acids2int=AMINO_ACIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba9ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"train\"], dtype=torch.long)\n",
    "valid_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"valid\"], dtype=torch.long)\n",
    "test_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"test\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48bf51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_train = collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735f442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(train_idx), \n",
    "                         batch_size=t.batch_size, collate_fn=coll_train, num_workers=t.num_workers)\n",
    "validloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(valid_idx), \n",
    "                         batch_size=t.batch_size, collate_fn=collate_fn, num_workers=t.num_workers)\n",
    "testloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(test_idx), \n",
    "                        batch_size=t.batch_size, collate_fn=collate_fn, num_workers=t.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1adaf8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca1cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=8347, num_edges=17396,\n",
       "       ndata_schemes={'x': Scheme(shape=(26,), dtype=torch.float32)}\n",
       "       edata_schemes={'edge_attr': Scheme(shape=(8,), dtype=torch.float32)}),\n",
       " tensor([357, 162,  29, 162, 351, 178, 155, 351, 376, 162,  65, 369, 198,  25,\n",
       "         162, 157, 330, 233, 243, 109, 190, 271, 240, 218,  62,  65,  65,  47,\n",
       "         247,  62, 190, 372, 337,  85, 166, 190, 351, 341, 351, 162, 118, 266,\n",
       "         155, 282,  84, 361,  62, 351,  84, 277]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "198caa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigDict()\n",
    "config[\"model\"] = m\n",
    "config[\"training\"] = t\n",
    "config[\"data\"] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-10-05 15:14:30.029528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-10-05 15:14:30.029557: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gilmer</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dfstransformer/enzymes-n200\" target=\"_blank\">https://wandb.ai/dfstransformer/enzymes-n200</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dfstransformer/enzymes-n200/runs/39dzaw6q\" target=\"_blank\">https://wandb.ai/dfstransformer/enzymes-n200/runs/39dzaw6q</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer/notebooks/selfattn/wandb/run-20211005_151428-39dzaw6q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(mode=mode, project=project, entity=\"dfstransformer\", \n",
    "                 name=name, config=config.to_dict(), job_type=\"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a92cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss(ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df6e9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y, ce=ce):\n",
    "    return ce(pred, y)\n",
    "\n",
    "def acc(pred, y):\n",
    "    return torch.sum(torch.argmax(pred, dim=1) == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:%d'%t.gpu_id if torch.cuda.is_available()  else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "998ec1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gilmer(**m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2934c934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accumulate_grads: 2\n",
       "alpha: 0.0\n",
       "batch_size: 50\n",
       "clip_gradient: 0.5\n",
       "decay_factor: 0.8\n",
       "es_improvement: 0.0\n",
       "es_path: null\n",
       "es_patience: 30\n",
       "es_period: 203\n",
       "fingerprint: cls\n",
       "gpu_id: null\n",
       "load_last: false\n",
       "lr: 0.003\n",
       "lr_adjustment_period: 203\n",
       "lr_patience: 3\n",
       "n_epochs: 1000\n",
       "num_workers: 8\n",
       "seed: 123\n",
       "wdecay_encoder: 0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57f93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainloader, loss, validloader=validloader, metrics={'acc': acc}, es_argument=lambda log: -log['valid-acc'], wandb_run = run, **t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss 5.605309 0.0800:  10%|██████████████▋                                                                                                                               | 21/203 [00:26<03:45,  1.24s/it]"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(trainer.es_path+'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, loader):\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        ys = []\n",
    "        for data in tqdm.tqdm(loader):\n",
    "            data = [to_cuda(dd, device) for dd in data]\n",
    "            pred = model(*data[:-1])\n",
    "            pred = torch.argmax(pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            y = data[-1].detach().cpu().numpy().tolist()\n",
    "            preds += pred\n",
    "            ys += y\n",
    "    return (np.asarray(preds) == np.asarray(ys)).sum()/len(ys)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865643ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'Valid Accuracy': compute_acc(model, validloader)})\n",
    "run.log({'Test Accuracy': compute_acc(model, testloader)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_acc(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca129e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_acc(model, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde966bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

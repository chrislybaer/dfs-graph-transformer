{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers\n",
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import yaml\n",
    "import functools\n",
    "from ml_collections import ConfigDict\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "\n",
    "sys.path = ['../../src'] + sys.path\n",
    "from dfs_transformer import DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, Trainer, to_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32661b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../config/selfattn/finetune_ogb.yaml'\n",
    "with open(fname) as file:\n",
    "    config = ConfigDict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2957919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accumulate_grads: 2\n",
       "batch_size: 50\n",
       "clip_gradient: 0.5\n",
       "decay_factor: 0.8\n",
       "es_improvement: 0.0\n",
       "es_path: null\n",
       "es_patience: 10\n",
       "fingerprint: cls\n",
       "gpu_id: 0\n",
       "load_last: true\n",
       "lr: 0.0003\n",
       "lr_head: 0.003\n",
       "lr_patience: 3\n",
       "lr_pretrained: 0.0003\n",
       "minimal_lr: 6.0e-08\n",
       "n_classes: 349\n",
       "n_epochs: 25\n",
       "n_frozen: 5\n",
       "path: ../../results/ogbn_mag/timeout1/\n",
       "pretrained_class: DFSCodeSeq2SeqFC\n",
       "pretrained_dir: null\n",
       "pretrained_entity: dfstransformer\n",
       "pretrained_model: rnd2min\n",
       "pretrained_project: ogbn-mag\n",
       "pretrained_yaml: null\n",
       "require_min_dfs_code: false\n",
       "seed: 123\n",
       "strict: true\n",
       "use_local_yaml: false\n",
       "weight_decay: 0.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15f3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pretrained_project = 'pubchem'\n",
    "config.pretrained_model = 'rnd2min2-10M-euler'\n",
    "config.es_period = 300\n",
    "config.lr = 0.000003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af22b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.require_min_dfs_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fb744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyRandom = not config.require_min_dfs_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8e1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_csv = pd.read_csv('../../datasets/ogbg_molhiv/mol.csv')\n",
    "\n",
    "dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\") \n",
    "split_idx = dataset.get_idx_split() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf60702",
   "metadata": {},
   "source": [
    "# check whether we get the correct splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ab4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train labels are identical.\n",
      "All valid labels are identical.\n",
      "All test labels are identical.\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    csv_labels = mol_csv[\"HIV_active\"][split_idx[split].numpy()].to_numpy()\n",
    "    ogb_labels = np.asarray([d.y.item() for d in dataset[split_idx[split]]])\n",
    "    if (ogb_labels == csv_labels).sum() == len(ogb_labels):\n",
    "        print(\"All %s labels are identical.\"%split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7752abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles = mol_csv[\"smiles\"][split_idx[\"train\"].numpy()].to_numpy()\n",
    "train_labels = mol_csv[\"HIV_active\"][split_idx[\"train\"].numpy()].to_numpy()\n",
    "valid_smiles = mol_csv[\"smiles\"][split_idx[\"valid\"].numpy()].to_numpy()\n",
    "valid_labels = mol_csv[\"HIV_active\"][split_idx[\"valid\"].numpy()].to_numpy()\n",
    "test_smiles = mol_csv[\"smiles\"][split_idx[\"test\"].numpy()].to_numpy()\n",
    "test_labels = mol_csv[\"HIV_active\"][split_idx[\"test\"].numpy()].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaddir = \"../../results/mymoleculenet_plus_features/hiv/1/\" # ogbg uses other smiles than deepchem...\n",
    "loaddir = None\n",
    "train = Deepchem2TorchGeometric(train_smiles, train_labels, loaddir=loaddir, onlyRandom=onlyRandom)\n",
    "valid = Deepchem2TorchGeometric(valid_smiles, valid_labels, loaddir=loaddir, onlyRandom=onlyRandom)\n",
    "test = Deepchem2TorchGeometric(test_smiles, test_labels, loaddir=loaddir, onlyRandom=onlyRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist, alpha=0.15):\n",
    "    node_batch = [] \n",
    "    edge_batch = []\n",
    "    y_batch = []\n",
    "    rnd_code_batch = []\n",
    "    for d in dlist:\n",
    "        node_batch += [d.node_features.clone()]\n",
    "        edge_batch += [d.edge_features.clone()]\n",
    "        rnd_code, rnd_index = dfs_code.rnd_dfs_code_from_torch_geometric(d, d.z.numpy().tolist(), \n",
    "                                                                         np.argmax(d.edge_attr.numpy(), axis=1).tolist())\n",
    "        rnd_code = torch.tensor(np.asarray(rnd_code), dtype=torch.long)\n",
    "        rnd_code_batch += [rnd_code]\n",
    "        y_batch += [d.y.clone()]\n",
    "    y = torch.cat(y_batch).unsqueeze(1)\n",
    "    y = (1-alpha)*y + alpha/2\n",
    "    return rnd_code_batch, node_batch, edge_batch, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd34ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train, shuffle=True, batch_size=config.batch_size, collate_fn=collate_fn, num_workers=8)\n",
    "validloader = DataLoader(valid, shuffle=False, batch_size=config.batch_size, collate_fn=collate_fn, num_workers=8)\n",
    "testloader = DataLoader(test, shuffle=False, batch_size=config.batch_size, collate_fn=collate_fn, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"rnd2min2-10M-euler-labelsmoothing\"\n",
    "mode = \"online\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93051dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pretrained model\n",
    "run = wandb.init(mode=mode, \n",
    "                 project=config.pretrained_project, \n",
    "                 entity=config.pretrained_entity, \n",
    "                 job_type=\"inference\")\n",
    "model_at = run.use_artifact(config.pretrained_model + \":latest\")\n",
    "model_dir = model_at.download()\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dir+\"/config.yaml\") as file:\n",
    "    mconfig = ConfigDict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ca611",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model = mconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(mode=mode, project=\"ogbg-hiv\", entity=\"dfstransformer\", \n",
    "                 name=name, config=config.to_dict(), job_type=\"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mconfig.model\n",
    "t = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "bce = nn.BCEWithLogitsLoss()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c39aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPlusHead(nn.Module):\n",
    "    def __init__(self, encoder, n_encoding, n_classes, fingerprint='cls'):\n",
    "        super(TransformerPlusHead, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = nn.Linear(n_encoding, n_classes)\n",
    "        self.fingerprint = fingerprint\n",
    "    \n",
    "    def forward(self, C, N, E):\n",
    "        features = self.encoder.encode(C, N, E, method=self.fingerprint)\n",
    "        output = self.head(features)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afc0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4beee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.eval({'y_true':data[-1], 'y_pred':data[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluator.expected_input_format)\n",
    "print(evaluator.expected_output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y, ce=bce):\n",
    "    return ce(pred, y)\n",
    "\n",
    "def acc(pred, y):\n",
    "    y_pred = (pred > 0.5).squeeze()\n",
    "    return (y_pred == y.squeeze()).sum()/len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:%d'%t.gpu_id if torch.cuda.is_available()  else 'cpu')\n",
    "encoder = DFSCodeSeq2SeqFC(**m)\n",
    "    \n",
    "if t.load_last and model_dir is not None:\n",
    "    encoder.load_state_dict(torch.load(model_dir+'/checkpoint.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ec1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerPlusHead(encoder, m.emb_dim*5*m.n_class_tokens, 1, fingerprint=t.fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del t.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainloader, loss, validloader=validloader, metrics={'acc': acc}, wandb_run = run, **t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(trainer.es_path+'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057715d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc(model, loader):\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        ys = []\n",
    "        for i, data in tqdm.tqdm(enumerate(testloader)):\n",
    "            data = [to_cuda(d, device) for d in data]\n",
    "            pred = model(*data[:-1])\n",
    "            preds += [pred.cpu()]\n",
    "            ys += [data[-1].cpu()]\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        ys = torch.cat(ys, dim=0)\n",
    "        return evaluator.eval({'y_true':ys, 'y_pred':preds})['rocauc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865643ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'Valid ROCAUC': compute_roc(model, validloader)})\n",
    "run.log({'Test ROCAUC': compute_roc(model, testloader)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48ba41",
   "metadata": {},
   "source": [
    "#store config and model\n",
    "with open(t.es_path+'config.yaml', 'w') as f:\n",
    "    yaml.dump(config.to_dict(), f, default_flow_style=False)\n",
    "if name is not None and mode != \"offline\":\n",
    "    trained_model_artifact = wandb.Artifact(name, type=\"model\", description=\"trained selfattn model\")\n",
    "    trained_model_artifact.add_dir(t.es_path)\n",
    "    run.log_artifact(trained_model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8f4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61e252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

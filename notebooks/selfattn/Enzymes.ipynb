{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers\n",
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import yaml\n",
    "import functools\n",
    "from ml_collections import ConfigDict\n",
    "sys.path = ['../../src'] + sys.path\n",
    "from dfs_transformer import DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, Trainer, to_cuda, Enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist):\n",
    "    node_batch = [] \n",
    "    edge_batch = []\n",
    "    y_batch = []\n",
    "    code_batch = []\n",
    "    for d in dlist:\n",
    "        node_batch += [d.node_features.clone()]\n",
    "        edge_batch += [d.edge_features.clone()]\n",
    "        code_batch += [d.min_dfs_code.clone()]\n",
    "        y_batch += [d.y]\n",
    "    return code_batch, node_batch, edge_batch, torch.tensor(y_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5de03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConfigDict()\n",
    "t = ConfigDict()\n",
    "d = ConfigDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"class\"] = \"DFSCodeSeq2SeqFC\"\n",
    "m[\"n_atoms\"] = 122\n",
    "m[\"n_bonds\"] = 8\n",
    "m[\"emb_dim\"] = 120\n",
    "m[\"nhead\"] = 12\n",
    "m[\"nlayers\"] = 6\n",
    "m[\"max_nodes\"] = 200\n",
    "m[\"max_edges\"] = 600\n",
    "m[\"dim_feedforward\"] = 2048\n",
    "m[\"missing_value\"] = None\n",
    "m[\"n_node_features\"] = 122\n",
    "m[\"n_edge_features\"] = 8\n",
    "m[\"n_class_tokens\"] = 1 \n",
    "m[\"use_min\"] = True\n",
    "\n",
    "t[\"batch_size\"] = 50\n",
    "t[\"gpu_id\"] = 0\n",
    "t[\"load_last\"] = False\n",
    "t[\"fingerprint\"] = \"cls\"\n",
    "t[\"accumulate_grads\"] = 2\n",
    "t[\"alpha\"] = 0\n",
    "t[\"clip_gradient\"] = 0.5\n",
    "t[\"decay_factor\"] = 0.8\n",
    "t[\"es_improvement\"] = 0.0\n",
    "t[\"es_path\"] = None\n",
    "t[\"es_patience\"] = 10\n",
    "t[\"es_period\"] = 166\n",
    "t[\"lr_head\"] = 0.003\n",
    "t[\"lr_encoder\"] = 0.0003\n",
    "t[\"lr_patience\"] = 3\n",
    "t[\"lr_adjustment_period\"] = 166\n",
    "t[\"n_epochs\"] = 25\n",
    "t[\"struct\"] = True\n",
    "t[\"seed\"] = 123\n",
    "t[\"num_workers\"] = 8\n",
    "\n",
    "d[\"n_classes\"] = 384\n",
    "d[\"path\"] = \"/mnt/ssd/datasets/enzyme/min_dfs_transformer_preprocessed_n200_dleq4.5.pkl\"\n",
    "d[\"n_edge_types\"] = 8\n",
    "d[\"n_node_types\"] = 122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76223e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"online\"\n",
    "name = \"dfstransformer\"\n",
    "project = \"enzymes-n200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Enzymes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24930e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"train\"], dtype=torch.long)\n",
    "valid_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"valid\"], dtype=torch.long)\n",
    "test_idx = torch.tensor([idx for idx, d in enumerate(dataset) if d.split == \"test\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a82783",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(train_idx), \n",
    "                         batch_size=t.batch_size, collate_fn=collate_fn, num_workers=t.num_workers)\n",
    "validloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(valid_idx), \n",
    "                         batch_size=t.batch_size, collate_fn=collate_fn, num_workers=t.num_workers)\n",
    "testloader = DataLoader(dataset, sampler=torch.utils.data.SubsetRandomSampler(test_idx), \n",
    "                        batch_size=t.batch_size, collate_fn=collate_fn, num_workers=t.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigDict()\n",
    "config[\"model\"] = m\n",
    "config[\"training\"] = t\n",
    "config[\"data\"] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(mode=mode, project=project, entity=\"dfstransformer\", \n",
    "                 name=name, config=config.to_dict(), job_type=\"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss(ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c39aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPlusHead(nn.Module):\n",
    "    def __init__(self, encoder, n_classes, fingerprint='cls'):\n",
    "        super(TransformerPlusHead, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        n_encoding = encoder.get_n_encoding(fingerprint)\n",
    "        self.head = nn.Linear(n_encoding, n_classes)\n",
    "        self.fingerprint = fingerprint\n",
    "    \n",
    "    def forward(self, C, N, E):\n",
    "        features = self.encoder.encode(C, N, E, method=self.fingerprint)\n",
    "        output = self.head(features)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y, ce=ce):\n",
    "    return ce(pred, y)\n",
    "\n",
    "def acc(pred, y):\n",
    "    return torch.sum(torch.argmax(pred, dim=1) == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:%d'%t.gpu_id if torch.cuda.is_available()  else 'cpu')\n",
    "encoder = DFSCodeSeq2SeqFC(**m)\n",
    "    \n",
    "#if t.load_last and model_dir is not None:\n",
    "#    encoder.load_state_dict(torch.load(model_dir+'/checkpoint.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ec1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerPlusHead(encoder, d.n_classes, fingerprint=t.fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b18162",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = [\n",
    "    {'amsgrad': False,\n",
    "     'betas': (0.9,0.98),\n",
    "     'eps': 1e-09,\n",
    "     'lr': t.lr_encoder,\n",
    "     'params': model.encoder.parameters(),\n",
    "     'weight_decay': 0},\n",
    "    {'amsgrad': False,\n",
    "     'betas': (0.9, 0.999),\n",
    "     'eps': 1e-08,\n",
    "     'lr': t.lr_head,\n",
    "     'params': model.head.parameters(),\n",
    "     'weight_decay': 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainloader, loss, validloader=validloader, metrics={'acc': acc}, wandb_run = run, param_groups=param_groups, **t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(trainer.es_path+'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aee71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, loader):\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        ys = []\n",
    "        for data in tqdm.tqdm(loader):\n",
    "            data = [to_cuda(dd, device) for dd in data]\n",
    "            pred = model(*data[:-1])\n",
    "            pred = torch.argmax(pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            y = data[-1].detach().cpu().numpy().tolist()\n",
    "            preds += pred\n",
    "            ys += y\n",
    "        return (np.asarray(preds) == np.asarray(ys))/len(ys)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865643ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'Valid ROCAUC': compute_acc(model, validloader, evaluator)})\n",
    "run.log({'Test ROCAUC': compute_acc(model, testloader, evaluator)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66834d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.acids2int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

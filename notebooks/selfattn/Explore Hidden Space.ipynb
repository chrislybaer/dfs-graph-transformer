{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c42268",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f80d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers\n",
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import yaml\n",
    "import functools\n",
    "from ml_collections import ConfigDict\n",
    "sys.path = ['../../src'] + sys.path\n",
    "from dfs_transformer import DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, Trainer, to_cuda\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a108f5",
   "metadata": {},
   "source": [
    "# download pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76cea1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176b1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/28 18:31:39\tERROR\twandb.jupyter\tFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meth-compiler-opters\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">olive-meadow-621</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dfstransformer/pubchem\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dfstransformer/pubchem/runs/tukziz13\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem/runs/tukziz13</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2023/graph-transformer/notebooks/selfattn/wandb/run-20221028_183140-tukziz13</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bertloops0.3-10M-nofeats:latest, 95.62MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47843<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/chrisw/Documents/projects/2023/graph-transformer/notebooks/selfattn/wandb/run-20221028_183140-tukziz13/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/chrisw/Documents/projects/2023/graph-transformer/notebooks/selfattn/wandb/run-20221028_183140-tukziz13/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">olive-meadow-621</strong>: <a href=\"https://wandb.ai/dfstransformer/pubchem/runs/tukziz13\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem/runs/tukziz13</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(mode=\"online\", \n",
    "                 project=\"pubchem\", \n",
    "                 entity=\"dfstransformer\", \n",
    "                 job_type=\"inference\")\n",
    "model_at = run.use_artifact(\"bertloops0.3-10M-nofeats\" + \":latest\")\n",
    "model_dir = model_at.download()\n",
    "run.finish()\n",
    "features = None# \"chemprop\"\n",
    "n_molecules = 10\n",
    "n_samples = 200\n",
    "fingerprint = 'min-mean-max-std'\n",
    "load_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6572c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dir+\"/config.yaml\") as file:\n",
    "    config = ConfigDict(yaml.load(file, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ff8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:%d'%config.training.gpu_id if torch.cuda.is_available()  else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1852e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d00902",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DFSCodeSeq2SeqFC:\n\tMissing key(s) in state_dict: \"fcs.dfs_from.weight\", \"fcs.dfs_from.bias\", \"fcs.dfs_to.weight\", \"fcs.dfs_to.bias\", \"fcs.atomic_num_from.weight\", \"fcs.atomic_num_from.bias\", \"fcs.atomic_num_to.weight\", \"fcs.atomic_num_to.bias\", \"fcs.formal_charge_from.weight\", \"fcs.formal_charge_from.bias\", \"fcs.formal_charge_to.weight\", \"fcs.formal_charge_to.bias\", \"fcs.chiral_tag_from.weight\", \"fcs.chiral_tag_from.bias\", \"fcs.chiral_tag_to.weight\", \"fcs.chiral_tag_to.bias\", \"fcs.num_Hs_from.weight\", \"fcs.num_Hs_from.bias\", \"fcs.num_Hs_to.weight\", \"fcs.num_Hs_to.bias\", \"fcs.hybridization_from.weight\", \"fcs.hybridization_from.bias\", \"fcs.hybridization_to.weight\", \"fcs.hybridization_to.bias\", \"fcs.is_aromatic_from.weight\", \"fcs.is_aromatic_from.bias\", \"fcs.is_aromatic_to.weight\", \"fcs.is_aromatic_to.bias\", \"fcs.bond_type.weight\", \"fcs.bond_type.bias\". \n\tUnexpected key(s) in state_dict: \"fc_dfs_idx1.weight\", \"fc_dfs_idx1.bias\", \"fc_dfs_idx2.weight\", \"fc_dfs_idx2.bias\", \"fc_atom1.weight\", \"fc_atom1.bias\", \"fc_atom2.weight\", \"fc_atom2.bias\", \"fc_bond.weight\", \"fc_bond.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47799/120250071.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFSCodeSeq2SeqFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mload_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1605\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DFSCodeSeq2SeqFC:\n\tMissing key(s) in state_dict: \"fcs.dfs_from.weight\", \"fcs.dfs_from.bias\", \"fcs.dfs_to.weight\", \"fcs.dfs_to.bias\", \"fcs.atomic_num_from.weight\", \"fcs.atomic_num_from.bias\", \"fcs.atomic_num_to.weight\", \"fcs.atomic_num_to.bias\", \"fcs.formal_charge_from.weight\", \"fcs.formal_charge_from.bias\", \"fcs.formal_charge_to.weight\", \"fcs.formal_charge_to.bias\", \"fcs.chiral_tag_from.weight\", \"fcs.chiral_tag_from.bias\", \"fcs.chiral_tag_to.weight\", \"fcs.chiral_tag_to.bias\", \"fcs.num_Hs_from.weight\", \"fcs.num_Hs_from.bias\", \"fcs.num_Hs_to.weight\", \"fcs.num_Hs_to.bias\", \"fcs.hybridization_from.weight\", \"fcs.hybridization_from.bias\", \"fcs.hybridization_to.weight\", \"fcs.hybridization_to.bias\", \"fcs.is_aromatic_from.weight\", \"fcs.is_aromatic_from.bias\", \"fcs.is_aromatic_to.weight\", \"fcs.is_aromatic_to.bias\", \"fcs.bond_type.weight\", \"fcs.bond_type.bias\". \n\tUnexpected key(s) in state_dict: \"fc_dfs_idx1.weight\", \"fc_dfs_idx1.bias\", \"fc_dfs_idx2.weight\", \"fc_dfs_idx2.bias\", \"fc_atom1.weight\", \"fc_atom1.bias\", \"fc_atom2.weight\", \"fc_atom2.bias\", \"fc_bond.weight\", \"fc_bond.bias\". "
     ]
    }
   ],
   "source": [
    "model = DFSCodeSeq2SeqFC(**m)\n",
    "if load_flag:\n",
    "    model.load_state_dict(torch.load(model_dir+'/checkpoint.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8dbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c315298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"number of trainable parameters %d\"%params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8208f37",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"../../datasets/mymoleculenet/bbbp/0/train.csv\")\n",
    "train_X, train_y = trainset[\"smiles\"].to_numpy(), trainset[\"target\"].to_numpy()\n",
    "traindata = Deepchem2TorchGeometric(train_X, train_y, loaddir=\"../../results/mymoleculenet_plus_features/bbbp/1/\", features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889788ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = [d for d in traindata if d.edge_features.shape[0] == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b618ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist, n_samples=n_samples):\n",
    "    node_batch = [] \n",
    "    edge_batch = []\n",
    "    y_batch = []\n",
    "    code_batch = []\n",
    "    smiles = []\n",
    "    \n",
    "    for d in dlist:\n",
    "        smiles += d.smiles \n",
    "        for _ in range(n_samples):\n",
    "            edge_features = d.edge_features.clone()\n",
    "\n",
    "            code, index = dfs_code.rnd_dfs_code_from_torch_geometric(d, d.z.numpy().tolist(), \n",
    "                                                                     np.argmax(d.edge_attr.numpy(), axis=1).tolist())\n",
    "\n",
    "            code = torch.tensor(code, dtype=torch.long)\n",
    "            index = torch.tensor(index, dtype=torch.long)\n",
    "            code_batch += [code]\n",
    "            node_batch += [d.node_features.clone()]\n",
    "            edge_batch += [edge_features]\n",
    "            y_batch += [d.y.clone()]\n",
    "    y = torch.cat(y_batch).unsqueeze(1)\n",
    "    return smiles, code_batch, node_batch, edge_batch, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dacc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(traindata, batch_size=1, shuffle=False, pin_memory=False, \n",
    "                         collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd362e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = []\n",
    "encodings2 = []\n",
    "labels = []\n",
    "dfs_codes = []\n",
    "smiles = []\n",
    "iterator = iter(trainloader)\n",
    "for i in range(n_molecules):\n",
    "    d = next(iterator)\n",
    "    smiles += [d[0]]\n",
    "    d = d[1:]\n",
    "    d = [to_cuda(dd, device) for dd in d]\n",
    "    encodings.append(model.encode(*d[:-1], fingerprint).detach().cpu().numpy())\n",
    "    labels += len(d[0])*[i]\n",
    "    dfs1, dfs2, atm1, atm2, bnd = model(*d[:-1])\n",
    "    torch\n",
    "    print(dfs1.shape)\n",
    "    enc2 = torch.cat((dfs1.mean(dim=0), dfs2.mean(dim=0), atm1.mean(dim=0), atm2.mean(dim=0), bnd.mean(dim=0)), dim=1)\n",
    "    encodings2.append(enc2.detach().cpu().numpy())\n",
    "encodings = np.concatenate(encodings, axis=0)\n",
    "encodings2 = np.concatenate(encodings2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6b8db",
   "metadata": {},
   "source": [
    "# sklearn kmeans benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5595337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
    "                                 metric=\"euclidean\", sample_size=300,)\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
    "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\")\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encodings.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5543c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_molecules, n_init=4,\n",
    "                random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_molecules, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_molecules).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_molecules, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea59d1c",
   "metadata": {},
   "source": [
    "10K\n",
    "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
    "k-means++\t3.851s\t1299580\t0.959\t0.966\t0.962\t0.924\t0.962\t0.139\n",
    "random   \t2.292s\t1305407\t0.940\t0.970\t0.954\t0.870\t0.954\t0.135\n",
    "PCA-based\t0.554s\t1383451\t0.896\t0.927\t0.911\t0.802\t0.910\t0.103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d705069",
   "metadata": {},
   "source": [
    "100K init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
    "k-means++\t0.753s\t1613620\t0.873\t0.874\t0.874\t0.835\t0.871\t0.066\n",
    "random   \t0.349s\t1610052\t0.740\t0.763\t0.751\t0.606\t0.746\t0.075\n",
    "PCA-based\t0.165s\t1645957\t0.724\t0.760\t0.742\t0.577\t0.737\t0.071"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef031b2a",
   "metadata": {},
   "source": [
    "1M init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
    "k-means++\t5.437s\t1489769\t0.761\t0.782\t0.771\t0.621\t0.767\t0.047\n",
    "random   \t3.327s\t1493680\t0.810\t0.838\t0.824\t0.702\t0.820\t0.050\n",
    "PCA-based\t1.175s\t1571641\t0.736\t0.754\t0.745\t0.575\t0.740\t0.031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_molecules, n_init=4)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation=\"nearest\",\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3,\n",
    "            color=\"w\", zorder=10)\n",
    "plt.title(\"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "          \"Centroids are marked with white cross\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa82469",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9efc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),\n",
    "                 name)\n",
    "                for name, color in mcolors.CSS4_COLORS.items())\n",
    "names = [name for hsv, name in by_hsv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_2d = tsne.fit_transform(data)\n",
    "\n",
    "target_ids = range(n_molecules)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple']\n",
    "colors = names[::-1][0:10*n_molecules:10]\n",
    "for i, c, label in zip(target_ids, colors, target_ids):\n",
    "    #print(c)\n",
    "    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(smiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d9311",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(smiles[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c0adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd4be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7844993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "torch.multiprocessing.set_sharing_strategy('file_system') # this is important\n",
    "# ulimit -n 500000\n",
    "def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['/home/chrisw/Documents/projects/2021/graph-transformer/src'] + sys.path\n",
    "from dfs_transformer import EarlyStopping, DFSCodeSeq2SeqFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.max_nodes = 100\n",
    "config.max_edges = 200\n",
    "config.nlayers = 6\n",
    "config.emb_dim = 50\n",
    "config.nhead = 5\n",
    "config.dim_feedforward = 2*(5*config.emb_dim)\n",
    "config.lr = 0.0003\n",
    "config.n_epochs = 10000\n",
    "config.patience = 5\n",
    "config.factor = 0.95\n",
    "config.minimal_lr = 6e-8\n",
    "config.target_idx = 7\n",
    "config.batch_size = 512#256\n",
    "config.valid_patience = 100\n",
    "config.valid_minimal_improvement=0.00\n",
    "config.model_dir = '../models/chembl/transformer/mini/'\n",
    "config.num_workers = 4\n",
    "config.dfs_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ef93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a388e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_descriptor', 'file_system'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiprocessing.get_all_sharing_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85546446",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ssd/datasets/ChEMBL/ChEMBL100_noH/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55f04196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChEMBL100NoH(Dataset):\n",
    "    \"\"\"ChEMBL dataset of molecules and minimal DFS codes.\"\"\"\n",
    "    # create data structure that says which id is in which file...\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.fnames = glob.glob(path+\"CHEMBL*.pkl\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.fnames[idx], 'rb') as f:\n",
    "            d = pickle.load(f)\n",
    "        data = Data(x=torch.tensor(d['x']),\n",
    "                    z=torch.tensor(d['z']),\n",
    "                    edge_attr=torch.tensor(d['edge_attr']),\n",
    "                    edge_index=torch.tensor(d['edge_index'], dtype=torch.long),\n",
    "                    name=d['name'],\n",
    "                    min_dfs_code=torch.tensor(d['min_dfs_code']),\n",
    "                    min_dfs_index=torch.tensor(d['min_dfs_index'], dtype=torch.long),\n",
    "                    smiles=d['smiles'])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c51eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist):\n",
    "    x_batch = [] \n",
    "    z_batch = []\n",
    "    edge_attr_batch = []\n",
    "    rnd_code_batch = []\n",
    "    min_code_batch = []\n",
    "    for d in dlist:\n",
    "        rnd_code, rnd_index = dfs_code.rnd_dfs_code_from_torch_geometric(d, \n",
    "                                                                         d.z.numpy().tolist(), \n",
    "                                                                         np.argmax(d.edge_attr.numpy(), axis=1))\n",
    "        x_batch += [d.x]\n",
    "        z_batch += [d.z]#[nn.functional.one_hot(d.z, 118)]#118 elements in periodic table\n",
    "        edge_attr_batch += [d.edge_attr]\n",
    "        rnd_code_batch += [torch.tensor(rnd_code)]\n",
    "        min_code_batch += [d.min_dfs_code]\n",
    "    return rnd_code_batch, x_batch, z_batch, edge_attr_batch, min_code_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=1\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9342547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChEMBL100NoH(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec2606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=256, shuffle=False, pin_memory=False, collate_fn=collate_fn)\n",
    "                  # worker_init_fn=set_worker_sharing_strategy)\n",
    "#shuffle False -> huge speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a9f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda = lambda T: [t.cuda() for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bae3e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DFSCodeSeq2SeqFC(n_atoms=118, n_bonds=4, emb_dim=50, nhead=5, nlayers=6, max_nodes=100, max_edges=400,\n",
    "                         atom_encoder=nn.Embedding(118, 50), bond_encoder=nn.Linear(4, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09f5f8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.model_dir+'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cee73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optimizers.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "early_stopping = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                              path=config.model_dir+'checkpoint.pt')\n",
    "bce = torch.nn.BCEWithLogitsLoss()\n",
    "ce = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "softmax = nn.Softmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "829fe786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFSCodeSeq2SeqFC(\n",
       "  (encoder): DFSCodeEncoder(\n",
       "    (emb_dfs): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (emb_seq): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (emb_atom): Embedding(118, 50)\n",
       "    (emb_bond): Linear(in_features=4, out_features=50, bias=True)\n",
       "    (enc): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=250, out_features=250, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=250, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=250, bias=True)\n",
       "          (norm1): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((250,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_dfs_idx1): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (fc_dfs_idx2): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (fc_atom1): Linear(in_features=250, out_features=118, bias=True)\n",
       "  (fc_atom2): Linear(in_features=250, out_features=118, bias=True)\n",
       "  (fc_bond): Linear(in_features=250, out_features=4, bias=True)\n",
       "  (fc_eos): Linear(in_features=250, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80479251",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6c6aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rndc, x, z, eattr, minc = data\n",
    "rndc = to_cuda(rndc)\n",
    "z = to_cuda(z)\n",
    "eattr = to_cuda(eattr)\n",
    "minc = to_cuda(minc)\n",
    "#prepare labels\n",
    "minc = [torch.cat((c, (-1)*torch.ones((1, 8), dtype=torch.long, device=device)), dim=0) for c in minc]\n",
    "minc_seq = nn.utils.rnn.pad_sequence(minc, padding_value=-1)\n",
    "\n",
    "rndc = [torch.cat((c, (-1)*torch.ones((1, 8), dtype=torch.long, device=device)), dim=0) for c in rndc]\n",
    "rndc_seq = nn.utils.rnn.pad_sequence(rndc, padding_value=-1)\n",
    "#prediction\n",
    "dfs1, dfs2, atm1, atm2, bnd, eos = model(rndc, z, eattr)\n",
    "eos_label = (minc_seq[:,:,0] == (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "715fb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsidx1 = torch.argmax(softmax(dfs1), dim=2)\n",
    "dfsidx2 = torch.argmax(softmax(dfs2), dim=2)\n",
    "atmnr1 = torch.argmax(softmax(atm1), dim=2)\n",
    "atmnr2 = torch.argmax(softmax(atm2), dim=2)\n",
    "bndnr = torch.argmax(softmax(bnd), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6341491",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0ffe33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = minc_seq[:, :, 0][:, j] != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c7542a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  3,  0,  6,  0,  7,  8,  8,  8, 11, 12, 11],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndc_seq[:, :, 0][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bad5227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  3,  1,  0,  7,  8,  9, 10, 11, 11, 13, 14],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsidx1[:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a665c359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  2,  1,  1,  7,  8,  9, 10, 11, 11, 13, 14],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc_seq[:, :, 0][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "893d07ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndc_seq[:, :, 1][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d762a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  8],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsidx2[:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "56a8f1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  8],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc_seq[:, :, 1][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d0b7d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 7, 6], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndc_seq[:, :, 2][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d05caae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6, 6, 7, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atmnr1[:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3b09f05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6, 7, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc_seq[:, :, 2][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "088f4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6,  6, 17,  6,  6,  6,  8,  6,  6,  6,  6,  7,  7,  8],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndc_seq[:, :, 4][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "292804a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6,  6,  7,  8,  8,  8,  6,  6,  6,  6, 17,  6,  6,  6],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atmnr2[:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8387d66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6,  7,  7,  8,  6,  8,  6,  6,  6,  6, 17,  6,  6,  6],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc_seq[:, :, 4][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1909540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndc_seq[:, :, 3][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "630aa565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndnr[:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "23157c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minc_seq[:, :, 3][:, j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8b74b8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eos_label[:, j]==False) == mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df794b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: MAE/CA 4.238406: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:54<00:00,  1.73it/s]\n",
      "Epoch 2: MAE/CA 3.486167: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:04<00:00,  1.75it/s]\n",
      "Epoch 3: MAE/CA 3.134876: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:06<00:00,  1.75it/s]\n",
      "Epoch 4: MAE/CA 2.903316: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:04<00:00,  1.75it/s]\n",
      "Epoch 5: MAE/CA 2.726842: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:06<00:00,  1.75it/s]\n",
      "Epoch 6: MAE/CA 2.584999: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:02<00:00,  1.75it/s]\n",
      "Epoch 7: MAE/CA 2.470382: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:07<00:00,  1.75it/s]\n",
      "Epoch 8: MAE/CA 2.372168: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:04<00:00,  1.75it/s]\n",
      "Epoch 9: MAE/CA 2.292951: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:07<00:00,  1.75it/s]\n",
      "Epoch 10: MAE/CA 2.224090: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:03<00:00,  1.75it/s]\n",
      "Epoch 11: MAE/CA 2.164700: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:06<00:00,  1.75it/s]\n",
      "Epoch 12: MAE/CA 2.109461: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:01<00:00,  1.75it/s]\n",
      "Epoch 13: MAE/CA 2.061843: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:05<00:00,  1.75it/s]\n",
      "Epoch 14: MAE/CA 2.019750: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:11:31<00:00,  1.74it/s]\n",
      "Epoch 15: MAE/CA 1.980051: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7454/7454 [1:12:41<00:00,  1.71it/s]\n",
      "Epoch 16: MAE/CA 1.966633:   1%|█▉                                                                                                                                            | 104/7454 [01:02<1:13:09,  1.67it/s]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(config.n_epochs):  \n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm.tqdm(loader)\n",
    "        for i, data in enumerate(pbar):\n",
    "            rndc, x, z, eattr, minc = data\n",
    "            rndc = to_cuda(rndc)\n",
    "            z = to_cuda(z)\n",
    "            eattr = to_cuda(eattr)\n",
    "            minc = to_cuda(minc)\n",
    "            #prepare labels\n",
    "            minc = [torch.cat((c, (-1)*torch.ones((1, 8), dtype=torch.long, device=device)), dim=0) for c in minc]\n",
    "            minc_seq = nn.utils.rnn.pad_sequence(minc, padding_value=-1)\n",
    "            \n",
    "            #prediction\n",
    "            dfs1, dfs2, atm1, atm2, bnd, eos = model(rndc, z, eattr)\n",
    "            eos_label = (minc_seq[:,:,0] == (-1))\n",
    "            #minc_seq[eos_label] = 0\n",
    "            #print(np.unique(minc_seq[:,:,0].cpu().numpy()))\n",
    "            #print(np.unique(minc_seq[:,:,1].cpu().numpy()))\n",
    "            #print(np.unique(minc_seq[:,:,2].cpu().numpy()))\n",
    "            #print(np.unique(minc_seq[:,:,3].cpu().numpy()))\n",
    "            #print(np.unique(minc_seq[:,:,4].cpu().numpy()))\n",
    "            #TODO: use ignore_index\n",
    "            loss = ce(torch.reshape(dfs1, (-1, 100)), minc_seq[:, :, 0].view(-1)) \n",
    "            loss += ce(torch.reshape(dfs2, (-1, 100)), minc_seq[:, :, 1].view(-1))\n",
    "            loss += ce(torch.reshape(atm1, (-1, 118)), minc_seq[:, :, 2].view(-1))\n",
    "            loss += ce(torch.reshape(bnd, (-1, 4)), minc_seq[:, :, 3].view(-1))\n",
    "            loss += ce(torch.reshape(atm2, (-1, 118)), minc_seq[:, :, 4].view(-1))\n",
    "            loss += bce(eos, torch.unsqueeze(eos_label.float(), -1))\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optim.step()\n",
    "            epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "            \n",
    "            pbar.set_description('Epoch %d: CE %2.6f'%(epoch+1, epoch_loss))\n",
    "\n",
    "\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        early_stopping(epoch_loss, model)\n",
    "        curr_lr = list(optim.param_groups)[0]['lr']\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "        if curr_lr < config.minimal_lr:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt caught')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d84a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

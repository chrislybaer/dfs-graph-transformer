{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b287e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import _dfs_codes as dfs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimizers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ogb.graphproppred import Evaluator\n",
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "import dfs_code\n",
    "import networkx as nx\n",
    "\n",
    "from focal_loss.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982d0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['/home/chrisw/Documents/projects/2021/graph-transformer/src'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf44c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  44\n"
     ]
    }
   ],
   "source": [
    "from dfs_transformer import EarlyStopping\n",
    "from dfs_transformer import DFSCodeClassifier\n",
    "import wandb\n",
    "import random \n",
    "import os\n",
    "\n",
    "manualSeed = 44\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7909f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eager-bird-24</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chrisxx/molhiv-transformer\" target=\"_blank\">https://wandb.ai/chrisxx/molhiv-transformer</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chrisxx/molhiv-transformer/runs/1l4gncwc\" target=\"_blank\">https://wandb.ai/chrisxx/molhiv-transformer/runs/1l4gncwc</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer/notebooks/Pretraining/wandb/run-20210817_160503-1l4gncwc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='molhiv-transformer', entity='chrisxx')\n",
    "config = wandb.config\n",
    "config.nlayers = 6\n",
    "config.emb_dim = 50\n",
    "config.nhead = 5\n",
    "config.dim_feedforward = 500\n",
    "config.lr = 0.0003\n",
    "config.n_epochs = 1000\n",
    "config.patience = 5\n",
    "config.factor = 0.9\n",
    "config.minimal_lr = 6e-8\n",
    "config.target_idx = 7\n",
    "config.batch_size = 128\n",
    "config.valid_patience = 20\n",
    "config.valid_minimal_improvement=0.00\n",
    "config.model_dir = '../models/molhiv/transformer/1/'\n",
    "config.num_workers = 4\n",
    "config.dfs_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41162533",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f929c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplittedDataset(Dataset):\n",
    "    def __init__(self, D, S):\n",
    "        super().__init__()\n",
    "        self.D, self.S = D, S\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.S)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.D[self.S[idx]]\n",
    "\n",
    "\n",
    "class MolhivDFSCodeDataset(Dataset):\n",
    "    def __init__(self, max_nodes=40):\n",
    "        super().__init__()\n",
    "        self.maxN = max_nodes\n",
    "        self.molhiv = GraphPropPredDataset(name='ogbg-molhiv')\n",
    "        self.throw_labels = lambda code: list(map(lambda c: c[:2] + c[-3:], code))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.molhiv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        added_e, Edges = [], []\n",
    "        G, L = self.molhiv[idx]\n",
    "        \n",
    "        edge_index = []\n",
    "        elabels = []\n",
    "        efeats = []\n",
    "        for edge, feat in zip(G['edge_index'].T, G['edge_feat']):\n",
    "            if edge[0] < self.maxN and edge[1] < self.maxN:\n",
    "                edge_index.append(edge.tolist())\n",
    "                elabels.append(feat[0])\n",
    "                efeats.append(feat.tolist())\n",
    "        edge_index = np.asarray(edge_index).astype(np.int64).T\n",
    "        efeats = np.asarray(efeats)\n",
    "        vlabels = G['node_feat'][:self.maxN, 0].tolist()\n",
    "        \n",
    "        # only keep largest connected component\n",
    "        edges_coo = edge_index.copy().T\n",
    "        g = nx.Graph()\n",
    "        g.add_nodes_from(np.arange(len(vlabels)))\n",
    "        g.add_edges_from(edges_coo.tolist())\n",
    "\n",
    "        ccs = list(nx.connected_components(g))\n",
    "        largest_cc = ccs[np.argmax([len(cc) for cc in ccs])]\n",
    "        node_ids = np.asarray(list(largest_cc))\n",
    "\n",
    "        x = G['node_feat'][:min(G['num_nodes'], self.maxN)][node_ids]\n",
    "        z = x[:, 0]\n",
    "        edges_cc = []\n",
    "        edge_feats = []\n",
    "        edge_labels = []\n",
    "        old2new = {old:new for new, old in enumerate(node_ids)}\n",
    "        for idx, (u, v) in enumerate(edges_coo):\n",
    "            if u in node_ids and v in node_ids:\n",
    "                edges_cc += [[old2new[u], old2new[v]]]\n",
    "                edge_feats += [efeats[idx].tolist()]\n",
    "                edge_labels += [elabels[idx]]\n",
    "        edge_index = torch.tensor(edges_cc, dtype=torch.long).T\n",
    "        edge_attr = torch.tensor(edge_feats, dtype=torch.int32)\n",
    "\n",
    "\n",
    "        data = Data(x=x, z=z, pos=None, edge_index=edge_index,\n",
    "                    edge_attr=edge_attr, y=None)\n",
    "        \n",
    "        \n",
    "        #Edges, _ = dfs_code.min_dfs_code_from_torch_geometric(data, z.tolist(), edge_labels)\n",
    "        Edges, _ = dfs_code.rnd_dfs_code_from_torch_geometric(data, z.tolist(), edge_labels)\n",
    "        return torch.LongTensor(Edges), torch.tensor(x, dtype=torch.int32), edge_attr, L[0] \n",
    "    #C (code) #N (node features) #E (edge features) and label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5d2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = MolhivDFSCodeDataset(max_nodes=400)\n",
    "data_split = D.molhiv.get_idx_split()\n",
    "valdata = [D[i] for i in data_split['valid']]\n",
    "testdata = [D[i] for i in data_split['test']]\n",
    "traindata = [D[i] for i in data_split['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1347621",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(valdata, batch_size=config.batch_size, pin_memory=True, collate_fn=lambda x:x)\n",
    "test_loader = DataLoader(testdata, batch_size=config.batch_size//2, pin_memory=True, collate_fn=lambda x:x)\n",
    "train_loader = DataLoader(traindata, batch_size=config.batch_size//2, pin_memory=True, shuffle=True, collate_fn=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6971d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_h, val_h = [], []\n",
    "evaluator = Evaluator(name='ogbg-molhiv')\n",
    "to_cuda = lambda T: map(lambda t: t.cuda(), T)\n",
    "\n",
    "\n",
    "M = DFSCodeClassifier(1, config.emb_dim, config.nhead, config.nlayers, dim_feedforward=config.dim_feedforward, max_nodes=D.maxN, max_edges=1000).cuda()\n",
    "optim = optimizers.Adam(M.parameters(), lr=config.lr)#, betas=(0.9, 0.98))#, eps=1e-7)\n",
    "\n",
    "lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "early_stopping = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                              path=config.model_dir+'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276104cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(alpha=2, gamma=5)\n",
    "criterion = nn.BCELoss(weight=torch.FloatTensor([0.5, 14.5]))\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f7ec331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(loader, model):\n",
    "    M = model\n",
    "    val_roc = 0\n",
    "    with torch.no_grad():\n",
    "        full_preds, target = [], []\n",
    "        for batch in tqdm(loader):\n",
    "            C, N, E, y = zip(*batch)\n",
    "            y = torch.Tensor(y).cuda()\n",
    "            pred = M(to_cuda(C), to_cuda(N), to_cuda(E)).squeeze()\n",
    "            target.extend(y.cpu().tolist())\n",
    "            full_preds.extend((1. * (0.5 < torch.sigmoid(pred))).cpu().tolist())\n",
    "\n",
    "        val_roc = evaluator.eval({'y_true': np.expand_dims(target, axis=1),\n",
    "                                  'y_pred': np.expand_dims(full_preds, axis=1)})['rocauc']\n",
    "    return val_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb81310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 515/515 [01:07<00:00,  7.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:02<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 - loss: 0.0025405556496590205 - val: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████████████████████▋                                                                                                                                 | 128/515 [00:16<00:59,  6.49it/s]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(config.n_epochs):  \n",
    "        M.train()\n",
    "        tot_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "\n",
    "            C, N, E, y = zip(*batch)\n",
    "            y = torch.Tensor(y).cuda()\n",
    "            pred = M(to_cuda(C), to_cuda(N), to_cuda(E)).squeeze()\n",
    "            optim.zero_grad()\n",
    "            #loss = nn.BCELoss(weight=14*y+.5)(torch.sigmoid(pred), y) #weight=14*y+.5\n",
    "            #loss = criterion(torch.sigmoid(pred), y)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tot_loss += loss.item()\n",
    "\n",
    "        M.eval()\n",
    "        val_roc = score(val_loader, M)\n",
    "\n",
    "        epoch += 1\n",
    "        val_h.append(val_roc)\n",
    "        loss_h.append(tot_loss / len(data_split['train']))\n",
    "\n",
    "        lr_scheduler.step(tot_loss)\n",
    "        early_stopping(-val_roc, M)\n",
    "        curr_lr = list(optim.param_groups)[0]['lr']\n",
    "\n",
    "\n",
    "        wandb.log({'BCE':loss_h[-1], \n",
    "                   'ROCAUC valid':val_roc,\n",
    "                   'learning rate':curr_lr})\n",
    "\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "        if curr_lr < config.minimal_lr:\n",
    "            break\n",
    "\n",
    "        print(f'\\nepoch: {len(loss_h)} - loss: {loss_h[-1]} - val: {val_h[-1]}', flush=True)\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt caught')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.load_state_dict(torch.load(config.model_dir+'checkpoint.pt'))\n",
    "M.eval()\n",
    "\n",
    "test_roc = score(test_loader, M)\n",
    "\n",
    "\n",
    "print(f'\\ntest AUROC: {test_roc} at best val epoch {np.argmax(val_h)+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb334e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7844993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "#torch.multiprocessing.set_sharing_strategy('file_system') # this is important on local machine\n",
    "#def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "#    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 14:41:40.010184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-01 14:41:40.010213: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = ['../../src'] + sys.path\n",
    "from dfs_transformer import EarlyStopping, DFSCodeSeq2SeqFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-09-01 14:41:57.182046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-01 14:41:57.182073: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fine-voice-77</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chrisxx/chembl\" target=\"_blank\">https://wandb.ai/chrisxx/chembl</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chrisxx/chembl/runs/2wxw4sh2\" target=\"_blank\">https://wandb.ai/chrisxx/chembl/runs/2wxw4sh2</a><br/>\n",
       "                Run data is saved locally in <code>/home/wendlerc/2021/graph-transformer/notebooks/Pretraining/wandb/run-20210901_144153-2wxw4sh2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='chembl', entity='chrisxx')\n",
    "\n",
    "config = wandb.config\n",
    "config.n_atoms = 118\n",
    "config.n_bonds = 4\n",
    "config.emb_dim = 120\n",
    "config.nhead = 12\n",
    "config.nlayers = 6\n",
    "config.max_nodes = 400\n",
    "config.max_edges = 600\n",
    "config.dim_feedforward = 2048\n",
    "config.lr = 0.000011111\n",
    "config.n_epochs = 10000\n",
    "config.lr_adjustment_period = 500\n",
    "config.patience = 5\n",
    "config.factor = 0.96\n",
    "config.minimal_lr = 6e-8\n",
    "config.batch_size = 100\n",
    "config.accumulate_grads = 2\n",
    "config.valid_patience = 10000\n",
    "config.valid_minimal_improvement=0.00\n",
    "config.model_dir = '../../models/chemblH/better_transformer/medium/'\n",
    "config.path = \"/mnt/project/chembl64/leq200_timeout10_sanity\"\n",
    "config.graph_pattern = \"/home/wendlerc/ChEMBL/preprocessedPlusHs_split%d.pt\"\n",
    "config.csv_file = \"/home/wendlerc/ChEMBL/small_molecules.csv\"\n",
    "config.pretrained_dir = \"../../models/chembl/better_transformer/medium/\"\n",
    "config.num_workers = 0\n",
    "config.prefetch_factor = 2\n",
    "config.persistent_workers = False\n",
    "config.load_last = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ef93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a388e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_descriptor', 'file_system'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiprocessing.get_all_sharing_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f04196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChEMBL(InMemoryDataset):\n",
    "    def __init__(self, fname):\n",
    "        super().__init__()\n",
    "        self.data, self.slices = torch.load(fname)\n",
    "\n",
    "class ChEMBL100NoH(Dataset):\n",
    "    \"\"\"ChEMBL dataset of molecules and minimal DFS codes.\"\"\"\n",
    "    # create data structure that says which id is in which file...\n",
    "    def __init__(self, path=config.path,\n",
    "                       graph_pattern=config.graph_pattern, \n",
    "                       csv_file=config.csv_file, \n",
    "                       idx_start=0,\n",
    "                       idx_max=64,\n",
    "                       transform=None):\n",
    "        self.path = path\n",
    "        self.fnames = glob.glob(path+\"CHEMBL*.pkl\")\n",
    "        self.data = []\n",
    "        self.csv_file = csv_file\n",
    "        self.path = path\n",
    "        self.graph_pattern = graph_pattern \n",
    "        self.idx_start = idx_start\n",
    "        self.idx_max = idx_max\n",
    "        self.prepare()\n",
    "        \n",
    "        \n",
    "    def prepare(self):\n",
    "        codes_all = {}\n",
    "        i2didx = {}\n",
    "        for i in tqdm.tqdm(range(self.idx_start, self.idx_max)):\n",
    "            dname = glob.glob(config.path+\"/%d/min_dfs_codes_split*.json\"%(i+1))[0]\n",
    "            didx = int(dname.split(\"split\")[-1][:-5])\n",
    "            i2didx[i] = didx\n",
    "            with open(dname, 'r') as f:\n",
    "                codes = json.load(f)\n",
    "                for key, val in codes.items():\n",
    "                    codes_all[key] = val\n",
    "        graph_pattern = self.graph_pattern\n",
    "        df = pd.read_csv(self.csv_file, delimiter=';', low_memory=False)\n",
    "        chembl2smiles = {cid:smiles for cid, smiles in zip(df['ChEMBL ID'], df['Smiles'])}\n",
    "        for i in range(self.idx_start, self.idx_max):\n",
    "            dataset = ChEMBL(graph_pattern%i2didx[i])\n",
    "            print(i)\n",
    "            for data in tqdm.tqdm(dataset):\n",
    "                if data.name in codes_all:\n",
    "                    code = codes_all[data.name]\n",
    "                    d = {'x':data.x.numpy(),\n",
    "                          'z':data.z.numpy(),\n",
    "                          'edge_attr': data.edge_attr.numpy(),\n",
    "                          'edge_index': data.edge_index.numpy(),\n",
    "                          'name':data.name,\n",
    "                          'min_dfs_code': np.asarray(code['min_dfs_code']),\n",
    "                          'min_dfs_index': np.asarray(code['dfs_index']),\n",
    "                          'smiles': chembl2smiles[data.name]}\n",
    "                    data_ = Data(x=torch.tensor(d['x']),\n",
    "                                z=torch.tensor(d['z']),\n",
    "                                edge_attr=torch.tensor(d['edge_attr']),\n",
    "                                edge_index=torch.tensor(d['edge_index'], dtype=torch.long),\n",
    "                                name=d['name'],\n",
    "                                min_dfs_code=torch.tensor(d['min_dfs_code']),\n",
    "                                min_dfs_index=torch.tensor(d['min_dfs_index'], dtype=torch.long),\n",
    "                                smiles=d['smiles'])\n",
    "                    self.data += [data_]   \n",
    "            del dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c51eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dlist):\n",
    "    x_batch = [] \n",
    "    z_batch = []\n",
    "    edge_attr_batch = []\n",
    "    rnd_code_batch = []\n",
    "    min_code_batch = []\n",
    "    for d in dlist:\n",
    "        rnd_code, rnd_index = dfs_code.rnd_dfs_code_from_torch_geometric(d, \n",
    "                                                                         d.z.numpy().tolist(), \n",
    "                                                                         np.argmax(d.edge_attr.numpy(), axis=1))\n",
    "        x_batch += [d.x]\n",
    "        z_batch += [d.z]#[nn.functional.one_hot(d.z, 118)]#118 elements in periodic table\n",
    "        edge_attr_batch += [d.edge_attr]\n",
    "        rnd_code_batch += [torch.tensor(rnd_code)]\n",
    "        min_code_batch += [d.min_dfs_code]\n",
    "    return rnd_code_batch, x_batch, z_batch, edge_attr_batch, min_code_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=1\n",
    "device = torch.device('cuda:1' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9342547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 32/32 [01:46<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4755.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4828.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4872.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4852.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4827.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4899.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4810.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29917/29917 [00:06<00:00, 4728.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4767.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:22<00:00, 1328.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4956.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4934.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4760.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4710.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4692.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4626.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4652.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4529.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4707.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4657.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4707.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4605.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4571.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4640.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4645.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4701.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4717.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4668.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4739.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4782.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4736.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29916/29916 [00:06<00:00, 4725.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = ChEMBL100NoH(idx_start=16, idx_max=16+32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec2606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, \n",
    "                    batch_size=config.batch_size, \n",
    "                    shuffle=True, \n",
    "                    pin_memory=False, \n",
    "                    collate_fn=collate_fn,\n",
    "                    num_workers=config.num_workers, \n",
    "                    prefetch_factor=config.prefetch_factor, \n",
    "                    persistent_workers=config.persistent_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda = lambda T: [t.to(device) for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae3e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DFSCodeSeq2SeqFC(n_atoms=config.n_atoms,\n",
    "                         n_bonds=config.n_bonds, \n",
    "                         emb_dim=config.emb_dim, \n",
    "                         nhead=config.nhead, \n",
    "                         nlayers=config.nlayers, \n",
    "                         max_nodes=config.max_nodes, \n",
    "                         max_edges=config.max_edges,\n",
    "                         atom_encoder=nn.Embedding(config.n_atoms, config.emb_dim), \n",
    "                         bond_encoder=nn.Linear(config.n_bonds, config.emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ad67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.pretrained_dir is not None:\n",
    "    model.load_state_dict(torch.load(config.pretrained_dir+'checkpoint.pt', map_location=device))\n",
    "if config.load_last:\n",
    "    model.load_state_dict(torch.load(config.model_dir+'checkpoint.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cee73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optimizers.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "#lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "lr_scheduler = optimizers.lr_scheduler.ExponentialLR(optim, gamma=config.factor)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                              path=config.model_dir+'checkpoint.pt')\n",
    "bce = torch.nn.BCEWithLogitsLoss()\n",
    "ce = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "softmax = nn.Softmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "829fe786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFSCodeSeq2SeqFC(\n",
       "  (encoder): DFSCodeEncoder(\n",
       "    (emb_dfs): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (emb_seq): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (emb_atom): Embedding(118, 120)\n",
       "    (emb_bond): Linear(in_features=4, out_features=120, bias=True)\n",
       "    (mixer): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (enc): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_dfs_idx1): Linear(in_features=1200, out_features=400, bias=True)\n",
       "  (fc_dfs_idx2): Linear(in_features=1200, out_features=400, bias=True)\n",
       "  (fc_atom1): Linear(in_features=1200, out_features=118, bias=True)\n",
       "  (fc_atom2): Linear(in_features=1200, out_features=118, bias=True)\n",
       "  (fc_bond): Linear(in_features=1200, out_features=4, bias=True)\n",
       "  (fc_eos): Linear(in_features=1200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df794b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.726162:   6%|█                 | 501/8611 [03:22<55:49,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.727141:  12%|█▉               | 1001/8611 [06:39<47:49,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.724648:  17%|██▉              | 1501/8611 [09:55<48:29,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.723486:  23%|███▉             | 2001/8611 [13:10<40:48,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.722601:  29%|████▉            | 2501/8611 [16:27<40:24,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.722343:  35%|█████▉           | 3001/8611 [19:42<36:50,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.721426:  41%|██████▉          | 3501/8611 [22:59<37:21,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.720557:  46%|███████▉         | 4001/8611 [26:15<31:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 8 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.719677:  52%|████████▉        | 4501/8611 [29:31<27:14,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.719547:  58%|█████████▊       | 5001/8611 [32:48<22:53,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718849:  64%|██████████▊      | 5501/8611 [36:05<21:54,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 11 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718569:  70%|███████████▊     | 6001/8611 [39:21<17:26,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 12 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718231:  75%|████████████▊    | 6501/8611 [42:38<13:31,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 13 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718152:  81%|█████████████▊   | 7001/8611 [45:55<10:25,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 14 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718951:  87%|██████████████▊  | 7501/8611 [49:12<07:06,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 15 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718562:  93%|███████████████▊ | 8001/8611 [52:29<04:02,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 16 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.719005:  99%|████████████████▊| 8501/8611 [55:45<00:43,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 17 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.719210: 100%|█████████████████| 8611/8611 [56:28<00:00,  2.54it/s]\n",
      "Epoch 2: CE 0.642413:   0%|                  | 1/8611 [00:00<1:01:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 18 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: CE 0.722655:   6%|█                 | 501/8611 [03:15<52:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 19 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: CE 0.719823:  12%|█▉               | 1001/8611 [06:31<52:50,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 20 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: CE 0.717396:  17%|██▉              | 1501/8611 [09:48<44:20,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 21 out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: CE 0.717074:  19%|███▏             | 1628/8611 [10:38<45:40,  2.55it/s]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(config.n_epochs):  \n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm.tqdm(loader)\n",
    "        for i, data in enumerate(pbar):\n",
    "            if i % config.accumulate_grads == 0: #bei 0 wollen wir das\n",
    "                optim.zero_grad()\n",
    "            rndc, x, z, eattr, minc = data\n",
    "            rndc = to_cuda(rndc)\n",
    "            z = to_cuda(z)\n",
    "            eattr = to_cuda(eattr)\n",
    "            minc = to_cuda(minc)\n",
    "            #prepare labels\n",
    "            minc = [torch.cat((c, (-1)*torch.ones((1, 8), dtype=torch.long, device=device)), dim=0) for c in minc]\n",
    "            minc_seq = nn.utils.rnn.pad_sequence(minc, padding_value=-1)\n",
    "            \n",
    "            #prediction\n",
    "            dfs1, dfs2, atm1, atm2, bnd, eos = model(rndc, z, eattr)\n",
    "            eos_label = (minc_seq[:,:,0] == (-1))\n",
    "            loss = ce(torch.reshape(dfs1, (-1, config.max_nodes)), minc_seq[:, :, 0].view(-1)) \n",
    "            loss += ce(torch.reshape(dfs2, (-1, config.max_nodes)), minc_seq[:, :, 1].view(-1))\n",
    "            loss += ce(torch.reshape(atm1, (-1, config.n_atoms)), minc_seq[:, :, 2].view(-1))\n",
    "            loss += ce(torch.reshape(bnd, (-1, config.n_bonds)), minc_seq[:, :, 3].view(-1))\n",
    "            loss += ce(torch.reshape(atm2, (-1, config.n_atoms)), minc_seq[:, :, 4].view(-1))\n",
    "            loss += bce(eos, torch.unsqueeze(eos_label.float(), -1))\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            if (i+1) % config.accumulate_grads == 0:\n",
    "                optim.step() # bei 2 wollen wir das\n",
    "            epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "            \n",
    "            curr_lr = list(optim.param_groups)[0]['lr']\n",
    "            wandb.log({'loss':epoch_loss, \n",
    "                   'learning rate':curr_lr})\n",
    "            pbar.set_description('Epoch %d: CE %2.6f'%(epoch+1, epoch_loss))\n",
    "            \n",
    "            if i % config.lr_adjustment_period == 0:\n",
    "                early_stopping(epoch_loss, model)\n",
    "                \n",
    "        lr_scheduler.step()#(epoch_loss)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "        if curr_lr < config.minimal_lr:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model.state_dict(), config.model_dir+'_keyboardinterrupt.pt')\n",
    "    print('keyboard interrupt caught')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec20af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

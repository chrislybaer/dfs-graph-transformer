{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 16:05:49.338717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-09-08 16:05:49.338739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7844993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "#torch.multiprocessing.set_sharing_strategy('file_system') # this is important\n",
    "# ulimit -n 500000\n",
    "#def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "#    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = ['/home/chrisw/Documents/projects/2021/graph-transformer/src'] + sys.path\n",
    "from dfs_transformer import EarlyStopping, DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, collate_minc_rndc_features_y, DFSCodeSeq2SeqDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-09-08 16:05:53.325468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-09-08 16:05:53.325490: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">deep-mountain-100</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chrisxx/moleculenet10\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet10</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chrisxx/moleculenet10/runs/2dyycsku\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet10/runs/2dyycsku</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer/notebooks/Pretraining/selfattention/wandb/run-20210908_160552-2dyycsku</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='moleculenet10', entity='chrisxx')\n",
    "\n",
    "config = wandb.config\n",
    "config.n_atoms = 118\n",
    "config.n_bonds = 5\n",
    "config.emb_dim = 120\n",
    "config.nhead = 12\n",
    "config.nlayers = 6\n",
    "config.use_Hs = False\n",
    "config.max_nodes = 250\n",
    "config.max_edges = 500\n",
    "config.features = \"chemprop\" # chemprop 133 node features 14 edge featuers, old 127 5, none 118 5\n",
    "config.n_node_features = 133\n",
    "config.n_edge_features = 14\n",
    "config.max_nodes_data = np.inf\n",
    "config.max_edges_data = np.inf\n",
    "config.onlyRandom = True\n",
    "config.use_min = False\n",
    "config.dim_feedforward = 2048\n",
    "config.lr = 0.00003 # 10x smaller than the learning rate of the pretraining seems to be good\n",
    "config.pretrained_weight_decay = 0#0.1\n",
    "config.clip_gradient = 0.5\n",
    "config.n_epochs = 25\n",
    "config.patience = 3\n",
    "config.factor = 0.95\n",
    "config.minimal_lr = 6e-8\n",
    "config.batch_size = 50\n",
    "config.accumulate_grads = 1\n",
    "config.valid_patience = 5\n",
    "config.valid_minimal_improvement = 0.00\n",
    "config.pretrained_dir = \"../../../models/pubchem_mini/features_selfattention/medium/\"\n",
    "config.num_workers = 0\n",
    "config.load_last = False\n",
    "config.dataset = 'bbbp' # supported 'bbbp', 'clintox', 'hiv', 'tox21'\n",
    "config.model_dir = '../../../models/moleculenet/%s/pubchem_mini/features_selfattention/medium/'%config.dataset\n",
    "config.data_dir = \"../../../datasets/mymoleculenet/%s/\"%config.dataset\n",
    "config.seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=1\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda = lambda T: [t.cuda() for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed501ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_scaffold_split(dataset):\n",
    "    splitter = dc.splits.ScaffoldSplitter()\n",
    "    shuffled = dataset.complete_shuffle()\n",
    "    trainidx, valididx, testidx = splitter.split(shuffled)\n",
    "    train = shuffled.select(trainidx)\n",
    "    valid = shuffled.select(valididx)\n",
    "    test = shuffled.select(testidx)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data_dir is None:\n",
    "    if config.dataset == 'clintox':\n",
    "        tasks, datasets, transformers = dc.molnet.load_clintox(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "    elif config.dataset == 'tox21':\n",
    "        tasks, datasets, transformers = dc.molnet.load_tox21(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "    elif config.dataset == 'hiv':\n",
    "        tasks, datasets, transformers = dc.molnet.load_hiv(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "    elif config.dataset == 'bbbp':\n",
    "        tasks, datasets, transformers = dc.molnet.load_bbbp(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8985828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def score(loader, model, model_head, use_min=False):\n",
    "    val_roc = 0\n",
    "    with torch.no_grad():\n",
    "        full_preds, target = [], []\n",
    "        for batch in tqdm.tqdm(loader):\n",
    "            rndc, minc, z, eattr, y = batch\n",
    "            if use_min:\n",
    "                code = to_cuda(minc)\n",
    "            else:\n",
    "                code = to_cuda(rndc)\n",
    "            y = y.to(device)\n",
    "            features = model.encode(code, to_cuda(z), to_cuda(eattr)) # not clear whether to use minc or randc\n",
    "            pred = sigmoid(model_head(features)).squeeze()\n",
    "            \n",
    "            pred_np = pred.detach().cpu().numpy().tolist()\n",
    "            y_np = y.detach().cpu().numpy().tolist()\n",
    "            full_preds += pred_np\n",
    "            target += y_np\n",
    "\n",
    "        target = np.asarray(target)\n",
    "        full_preds = np.asarray(full_preds)\n",
    "        roc = roc_auc_score(target, full_preds)\n",
    "        prc = average_precision_score(target, full_preds)\n",
    "    return roc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67afc60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.718256:   3%|████▋                                                                                                                                                    | 1/33 [00:00<00:15,  2.10it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 10.91 GiB total capacity; 2.02 GiB already allocated; 38.12 MiB free; 2.16 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1750037/762149084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m#prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/2021/graph-transformer/src/dfs_transformer/transformers.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, C, N, E)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0meos\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# seq x batch x feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meos_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/2021/graph-transformer/src/dfs_transformer/transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, C, N, E, class_token, eos)\u001b[0m\n\u001b[1;32m     99\u001b[0m             src_key_padding_mask = torch.cat((torch.zeros((batch.shape[1], 1), dtype=torch.bool, device=batch.device), \n\u001b[1;32m    100\u001b[0m                                               src_key_padding_mask), dim=1) # n_batch x n_seq\n\u001b[0;32m--> 101\u001b[0;31m             self_attn = self.enc(torch.cat((class_token.expand(-1, batch.shape[1], -1), batch), dim=0),\n\u001b[0m\u001b[1;32m    102\u001b[0m                                  src_key_padding_mask=src_key_padding_mask)\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \"\"\"\n\u001b[0;32m--> 320\u001b[0;31m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[1;32m    321\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[1;32m    322\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1032\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5080\u001b[0m     \u001b[0;31m# (deep breath) calculate attention and out projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5081\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5082\u001b[0;31m     \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5083\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5084\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_scaled_dot_product_attention\u001b[0;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[1;32m   4823\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4824\u001b[0m     \u001b[0;31m# (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4825\u001b[0;31m     \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4826\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4827\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 10.91 GiB total capacity; 2.02 GiB already allocated; 38.12 MiB free; 2.16 GiB reserved in total by PyTorch)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Droppped streaming file chunk (see wandb/debug.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/chrisxx/moleculenet10/2dyycsku/file_stream\n",
      "Exception in thread FileStreamThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chrisw/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/chrisw/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/wandb/sdk/internal/file_stream.py\", line 313, in _thread_except_body\n",
      "    raise e\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/wandb/sdk/internal/file_stream.py\", line 307, in _thread_except_body\n",
      "    self._thread_body()\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/wandb/sdk/internal/file_stream.py\", line 281, in _thread_body\n",
      "    self._handle_response(\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/wandb/sdk/internal/file_stream.py\", line 320, in _handle_response\n",
      "    raise response\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/wandb/sdk/internal/file_stream.py\", line 419, in request_with_retry\n",
      "    response.raise_for_status()\n",
      "  File \"/home/chrisw/.cache/pypoetry/virtualenvs/graph-transformer-9jPERXQ--py3.8/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/files/chrisxx/moleculenet10/2dyycsku/file_stream\n"
     ]
    }
   ],
   "source": [
    "roc_avgs = []\n",
    "prc_avgs = []\n",
    "for rep in range(10):\n",
    "    model = DFSCodeSeq2SeqFC(n_atoms=config.n_atoms,\n",
    "                         n_bonds=config.n_bonds, \n",
    "                         emb_dim=config.emb_dim, \n",
    "                         nhead=config.nhead, \n",
    "                         nlayers=config.nlayers, \n",
    "                         max_nodes=config.max_nodes, \n",
    "                         max_edges=config.max_edges,\n",
    "                         atom_encoder=nn.Linear(config.n_node_features, config.emb_dim), \n",
    "                         bond_encoder=nn.Linear(config.n_edge_features, config.emb_dim))\n",
    "    if config.load_last:\n",
    "        model.load_state_dict(torch.load(config.pretrained_dir+'checkpoint.pt', map_location=device))\n",
    "        print('loaded pretrained model')\n",
    "    \n",
    "    model_head = nn.Linear(5*config.emb_dim, 1)\n",
    "    model_head.to(device)\n",
    "    model.to(device)\n",
    "    w_init = nn.utils.parameters_to_vector(model.parameters()).detach().clone()\n",
    "    \n",
    "    if config.data_dir is None:\n",
    "        trainset, validset, testset = get_random_scaffold_split(datasets[0])\n",
    "        train_X, train_y = trainset.X, trainset.y[:, -1]\n",
    "        valid_X, valid_y = validset.X, validset.y[:, -1]\n",
    "        test_X, text_y = testset.X, testset.y[:, -1]\n",
    "    else:\n",
    "        trainset = pd.read_csv(config.data_dir+\"%d/train.csv\"%rep)\n",
    "        validset = pd.read_csv(config.data_dir+\"%d/valid.csv\"%rep)\n",
    "        testset = pd.read_csv(config.data_dir+\"%d/test.csv\"%rep)\n",
    "        train_X, train_y = trainset[\"smiles\"].to_numpy(), trainset[\"target\"].to_numpy()\n",
    "        valid_X, valid_y = validset[\"smiles\"].to_numpy(), validset[\"target\"].to_numpy()\n",
    "        test_X, test_y = testset[\"smiles\"].to_numpy(), testset[\"target\"].to_numpy()\n",
    "        \n",
    "    \n",
    "    collate_fn = collate_minc_rndc_features_y\n",
    "\n",
    "    traindata = Deepchem2TorchGeometric(train_X, train_y, features=config.features, trimEdges=False, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    validdata = Deepchem2TorchGeometric(valid_X, valid_y, features=config.features, trimEdges=False, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    testdata = Deepchem2TorchGeometric(test_X, test_y, features=config.features, trimEdges=False, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    trainloader = DataLoader(traindata, batch_size=config.batch_size, shuffle=True, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    validloader = DataLoader(validdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    testloader = DataLoader(testdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    optim = optimizers.Adam(list(model.parameters()) + list(model_head.parameters()), lr=config.lr)\n",
    "    lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "    early_stopping_model = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                                  path=config.model_dir+'checkpoint_model.pt')\n",
    "    early_stopping_head = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                                  path=config.model_dir+'checkpoint_head.pt')\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    valid_scores = []\n",
    "    try:\n",
    "        for epoch in range(config.n_epochs):  \n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm.tqdm(trainloader)\n",
    "            model.train()\n",
    "            for i, data in enumerate(pbar):\n",
    "                if i % config.accumulate_grads == 0: \n",
    "                    optim.zero_grad()\n",
    "                rndc, minc, z, eattr, y = data\n",
    "                if config.use_min:\n",
    "                    code = to_cuda(minc)\n",
    "                else:\n",
    "                    code = to_cuda(rndc)\n",
    "                z = to_cuda(z)\n",
    "                eattr = to_cuda(eattr)\n",
    "                y = y.to(device)\n",
    "                #prediction\n",
    "                features = model.encode(code, z, eattr)\n",
    "                prediction = model_head(features).squeeze()\n",
    "                loss = bce(prediction, y)\n",
    "                if config.pretrained_weight_decay > 0:\n",
    "                    w_curr = nn.utils.parameters_to_vector(model.parameters())\n",
    "                    loss += config.pretrained_weight_decay * 0.5 * torch.sum((w_curr - w_init)**2)\n",
    "                loss.backward()\n",
    "                if config.clip_gradient is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip_gradient)\n",
    "                if (i + 1) % config.accumulate_grads == 0: \n",
    "                    optim.step()\n",
    "                epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "                pbar.set_description('Epoch %d: CE %2.6f'%(epoch+1, epoch_loss))\n",
    "            model.eval()\n",
    "            roc_auc_valid, prc_auc_valid = score(validloader, model, model_head, config.use_min) \n",
    "            valid_scores += [roc_auc_valid]\n",
    "            lr_scheduler.step(epoch_loss)\n",
    "            early_stopping_model(-roc_auc_valid, model)\n",
    "            early_stopping_head(-roc_auc_valid, model_head)\n",
    "            curr_lr = list(optim.param_groups)[0]['lr']\n",
    "            wandb.log({'loss':epoch_loss, 'roc_valid':roc_auc_valid, 'prc_valid':prc_auc_valid, 'learning rate':curr_lr}, \n",
    "                      step=config.n_epochs*rep + epoch)\n",
    "            print('ROCAUC',roc_auc_valid, 'PRCAUC', prc_auc_valid)\n",
    "\n",
    "            if early_stopping_model.early_stop:\n",
    "                break\n",
    "\n",
    "            if curr_lr < config.minimal_lr:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), config.model_dir+'_keyboardinterrupt.pt')\n",
    "        print('keyboard interrupt caught')\n",
    "        \n",
    "    model.load_state_dict(torch.load(config.model_dir+'checkpoint_model.pt'))\n",
    "    model_head.load_state_dict(torch.load(config.model_dir+'checkpoint_head.pt'))\n",
    "    model.eval()\n",
    "    roc_auc_valid, prc_auc_valid = score(testloader, model, model_head) \n",
    "    wandb.log({'roc_test':roc_auc_valid, 'prc_test':prc_auc_valid}, step=config.n_epochs*(rep+1))\n",
    "    \n",
    "    roc, prc = score(testloader, model, model_head, True)\n",
    "    wandb.log({'roc_test_min':roc, 'prc_test_min':prc}, step=config.n_epochs*(rep+1))\n",
    "    print('ROC, PRC VALID', score(validloader, model, model_head, True))\n",
    "    print('ROC, PRC TEST', score(testloader, model, model_head, True))\n",
    "    \n",
    "    avg_roc = 0\n",
    "    avg_prc = 0\n",
    "    for i in range(20):\n",
    "        roc, prc = score(testloader, model, model_head, False)\n",
    "        avg_roc += roc\n",
    "        avg_prc += prc\n",
    "    avg_roc /= 20\n",
    "    avg_prc /= 20 \n",
    "    roc_avgs += [avg_roc]\n",
    "    prc_avgs += [avg_prc]\n",
    "    wandb.log({'roc_test_avg20':avg_roc, 'prc_test_avg20':avg_prc}, step=config.n_epochs*(rep+1))\n",
    "    print('ROC, PRC TEST', avg_roc, avg_prc)\n",
    "    del model\n",
    "    del model_head\n",
    "wandb.log({'roc_test_avgavg':np.mean(roc_avgs), 'prc_test_avgavg':np.mean(prc_avgs)}, step=config.n_epochs*(rep+1))\n",
    "wandb.log({'roc_test_avgstd':np.std(roc_avgs), 'prc_test_avgstd':np.std(prc_avgs)}, step=config.n_epochs*(rep+1))\n",
    "wandb.run.summary[\"roc_test_mean\"] = np.mean(roc_avgs) \n",
    "wandb.run.summary[\"roc_test_std\"] = np.std(roc_avgs)\n",
    "wandb.run.summary[\"prc_test_mean\"] = np.mean(prc_avgs)\n",
    "wandb.run.summary[\"prc_test_std\"] = np.std(prc_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22081239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

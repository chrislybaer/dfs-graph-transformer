{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 00:23:46.471967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-08-31 00:23:46.471992: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7844993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import tqdm\n",
    "import copy\n",
    "#torch.multiprocessing.set_sharing_strategy('file_system') # this is important\n",
    "# ulimit -n 500000\n",
    "#def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "#    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['/home/chrisw/Documents/projects/2021/graph-transformer/src'] + sys.path\n",
    "from dfs_transformer import EarlyStopping, DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, collate_minc_rndc_y, DFSCodeSeq2SeqFCLegacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-08-31 00:24:11.330805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-08-31 00:24:11.330828: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dandy-thunder-42</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chrisxx/moleculenet10\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet10</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chrisxx/moleculenet10/runs/vin7gzph\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet10/runs/vin7gzph</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer/notebooks/Pretraining/wandb/run-20210831_002410-vin7gzph</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='moleculenet10', entity='chrisxx')\n",
    "\n",
    "config = wandb.config\n",
    "config.n_atoms = 118\n",
    "config.n_bonds = 4\n",
    "config.emb_dim = 120\n",
    "config.nhead = 12\n",
    "config.nlayers = 6\n",
    "config.use_Hs = True\n",
    "config.max_nodes = 400\n",
    "config.max_edges = 600\n",
    "config.max_nodes_data = 400\n",
    "config.max_edges_data = 600\n",
    "config.onlyRandom = True\n",
    "config.use_min = False # interestingly random seems to work better than using the minimal codes...\n",
    "config.dim_feedforward = 2048\n",
    "config.lr = 0.00003 # 10x smaller than the learning rate of the pretraining seems to be good\n",
    "config.clip_gradient = 0.5\n",
    "config.n_epochs = 25\n",
    "config.patience = 3\n",
    "config.factor = 0.95\n",
    "config.minimal_lr = 6e-8\n",
    "config.batch_size = 16\n",
    "config.valid_patience = 5\n",
    "config.valid_minimal_improvement = 0.00\n",
    "#config.pretrained_dir = '../../models/chembl/better_transformer/medium/neu/'\n",
    "config.pretrained_dir = '../../models/chemblH/better_transformer/medium/'\n",
    "config.num_workers = 0\n",
    "config.load_last = True\n",
    "config.dataset = 'hiv' # supported 'bbbp', 'clintox', 'hiv', 'tox21'\n",
    "config.model_dir = '../../models/moleculenetH/%s/better_transformer/medium/'%config.dataset\n",
    "config.seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=1\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda = lambda T: [t.cuda() for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed501ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_scaffold_split(dataset):\n",
    "    splitter = dc.splits.ScaffoldSplitter()\n",
    "    shuffled = dataset.complete_shuffle()\n",
    "    trainidx, valididx, testidx = splitter.split(shuffled)\n",
    "    train = shuffled.select(trainidx)\n",
    "    valid = shuffled.select(valididx)\n",
    "    test = shuffled.select(testidx)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == 'clintox':\n",
    "    tasks, datasets, transformers = dc.molnet.load_clintox(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "elif config.dataset == 'tox21':\n",
    "    tasks, datasets, transformers = dc.molnet.load_tox21(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "elif config.dataset == 'hiv':\n",
    "    tasks, datasets, transformers = dc.molnet.load_hiv(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)\n",
    "elif config.dataset == 'bbbp':\n",
    "    tasks, datasets, transformers = dc.molnet.load_bbbp(reload=False, featurizer=dc.feat.RawFeaturizer(True), splitter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8985828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def score(loader, model, model_head, use_min=False):\n",
    "    val_roc = 0\n",
    "    with torch.no_grad():\n",
    "        full_preds, target = [], []\n",
    "        for batch in tqdm.tqdm(loader):\n",
    "            rndc, minc, z, eattr, y = batch\n",
    "            if use_min:\n",
    "                code = to_cuda(minc)\n",
    "            else:\n",
    "                code = to_cuda(rndc)\n",
    "            y = y.to(device)\n",
    "            self_attn, features, eos = model.encode(code, to_cuda(z), to_cuda(eattr)) # not clear whether to use minc or randc\n",
    "            pred = sigmoid(model_head(features)).squeeze()\n",
    "            \n",
    "            pred_np = pred.detach().cpu().numpy().tolist()\n",
    "            y_np = y.detach().cpu().numpy().tolist()\n",
    "            full_preds += pred_np\n",
    "            target += y_np\n",
    "\n",
    "        target = np.asarray(target)\n",
    "        full_preds = np.asarray(full_preds)\n",
    "        roc = roc_auc_score(target, full_preds)\n",
    "        prc = average_precision_score(target, full_preds)\n",
    "    return roc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_avgs = []\n",
    "prc_avgs = []\n",
    "for rep in range(10):\n",
    "    model = DFSCodeSeq2SeqFC(n_atoms=config.n_atoms,\n",
    "                         n_bonds=config.n_bonds, \n",
    "                         emb_dim=config.emb_dim, \n",
    "                         nhead=config.nhead, \n",
    "                         nlayers=config.nlayers, \n",
    "                         max_nodes=config.max_nodes, \n",
    "                         max_edges=config.max_edges,\n",
    "                         atom_encoder=nn.Embedding(config.n_atoms, config.emb_dim), \n",
    "                         bond_encoder=nn.Linear(config.n_bonds, config.emb_dim))\n",
    "    if config.load_last:\n",
    "        model.load_state_dict(torch.load(config.pretrained_dir+'checkpoint.pt', map_location=device))\n",
    "    model_head = nn.Linear(5*config.emb_dim, 1)\n",
    "    model_head.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    trainset, validset, testset = get_random_scaffold_split(datasets[0])\n",
    "    collate_fn = collate_minc_rndc_y\n",
    "    traindata = Deepchem2TorchGeometric(trainset, -1, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    validdata = Deepchem2TorchGeometric(validset, -1, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    testdata = Deepchem2TorchGeometric(testset, -1, useHs=config.use_Hs, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    trainloader = DataLoader(traindata, batch_size=config.batch_size, shuffle=True, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    validloader = DataLoader(validdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    testloader = DataLoader(testdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    \n",
    "    optim = optimizers.Adam(list(model.parameters()) + list(model_head.parameters()), lr=config.lr)\n",
    "    lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "    early_stopping_model = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                                  path=config.model_dir+'checkpoint_model.pt')\n",
    "    early_stopping_head = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                                  path=config.model_dir+'checkpoint_head.pt')\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    valid_scores = []\n",
    "    try:\n",
    "        for epoch in range(config.n_epochs):  \n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm.tqdm(trainloader)\n",
    "            model.train()\n",
    "            for i, data in enumerate(pbar):\n",
    "                optim.zero_grad()\n",
    "                rndc, minc, z, eattr, y = data\n",
    "                if config.use_min:\n",
    "                    code = to_cuda(minc)\n",
    "                else:\n",
    "                    code = to_cuda(rndc)\n",
    "                z = to_cuda(z)\n",
    "                eattr = to_cuda(eattr)\n",
    "                y = y.to(device)\n",
    "                #prediction\n",
    "                self_attn, features, eos = model.encode(code, z, eattr)\n",
    "                prediction = model_head(features).squeeze()\n",
    "                loss = bce(prediction, y)\n",
    "\n",
    "                loss.backward()\n",
    "                if config.clip_gradient is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip_gradient)\n",
    "                optim.step()\n",
    "                epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "                pbar.set_description('Epoch %d: CE %2.6f'%(epoch+1, epoch_loss))\n",
    "            model.eval()\n",
    "            roc_auc_valid, prc_auc_valid = score(validloader, model, model_head, config.use_min) \n",
    "            valid_scores += [roc_auc_valid]\n",
    "            lr_scheduler.step(epoch_loss)\n",
    "            early_stopping_model(-roc_auc_valid, model)\n",
    "            early_stopping_head(-roc_auc_valid, model_head)\n",
    "            curr_lr = list(optim.param_groups)[0]['lr']\n",
    "            wandb.log({'loss':epoch_loss, 'roc_valid':roc_auc_valid, 'prc_valid':prc_auc_valid, 'learning rate':curr_lr}, \n",
    "                      step=config.n_epochs*rep + epoch)\n",
    "            print('ROCAUC',roc_auc_valid, 'PRCAUC', prc_auc_valid)\n",
    "\n",
    "            if early_stopping_model.early_stop:\n",
    "                break\n",
    "\n",
    "            if curr_lr < config.minimal_lr:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), config.model_dir+'_keyboardinterrupt.pt')\n",
    "        print('keyboard interrupt caught')\n",
    "        \n",
    "    model.load_state_dict(torch.load(config.model_dir+'checkpoint_model.pt'))\n",
    "    model_head.load_state_dict(torch.load(config.model_dir+'checkpoint_head.pt'))\n",
    "    model.eval()\n",
    "    roc_auc_valid, prc_auc_valid = score(testloader, model, model_head) \n",
    "    wandb.log({'roc_test':roc_auc_valid, 'prc_test':prc_auc_valid}, step=config.n_epochs*(rep+1))\n",
    "    \n",
    "    roc, prc = score(testloader, model, model_head, True)\n",
    "    wandb.log({'roc_test_min':roc, 'prc_test_min':prc}, step=config.n_epochs*(rep+1))\n",
    "    print('ROC, PRC VALID', score(validloader, model, model_head, True))\n",
    "    print('ROC, PRC TEST', score(testloader, model, model_head, True))\n",
    "    \n",
    "    avg_roc = 0\n",
    "    avg_prc = 0\n",
    "    for i in range(20):\n",
    "        roc, prc = score(testloader, model, model_head, False)\n",
    "        avg_roc += roc\n",
    "        avg_prc += prc\n",
    "    avg_roc /= 20\n",
    "    avg_prc /= 20 \n",
    "    roc_avgs += [avg_roc]\n",
    "    prc_avgs += [avg_prc]\n",
    "    wandb.log({'roc_test_avg20':avg_roc, 'prc_test_avg20':avg_prc}, step=config.n_epochs*(rep+1))\n",
    "    print('ROC, PRC TEST', avg_roc, avg_prc)\n",
    "    del model\n",
    "    del model_head\n",
    "wandb.log({'roc_test_avgavg':np.mean(roc_avgs), 'prc_test_avgavg':np.mean(prc_avgs)}, step=config.n_epochs*(rep+1))\n",
    "wandb.log({'roc_test_avgstd':np.std(roc_avgs), 'prc_test_avgstd':np.std(prc_avgs)}, step=config.n_epochs*(rep+1))\n",
    "wandb.run.summary[\"roc_test_mean\"] = np.mean(roc_avgs) \n",
    "wandb.run.summary[\"roc_test_std\"] = np.std(roc_avgs)\n",
    "wandb.run.summary[\"prc_test_mean\"] = np.mean(prc_avgs)\n",
    "wandb.run.summary[\"prc_test_std\"] = np.std(prc_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22081239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

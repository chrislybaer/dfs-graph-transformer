{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 15:04:07.156275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-08-27 15:04:07.156312: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import wandb\n",
    "import os\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7844993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfs_code\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import tqdm\n",
    "import copy\n",
    "#torch.multiprocessing.set_sharing_strategy('file_system') # this is important\n",
    "# ulimit -n 500000\n",
    "#def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "#    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['/home/chrisw/Documents/projects/2021/graph-transformer/src'] + sys.path\n",
    "from dfs_transformer import EarlyStopping, DFSCodeSeq2SeqFC, Deepchem2TorchGeometric, collate_minc_rndc_y, DFSCodeSeq2SeqFCLegacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69384b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisxx\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-08-27 15:04:11.594388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib:/opt/cuda/extras/CUPTI/lib64/:/opt/intel/lib:/opt/intel/mkl/lib/intel64:/opt/intel:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux:/opt/ibm/ILOG/CPLEX_Studio1210/cplex/python/3.7/x86-64_linux:/opt/intel/clck_latest/lib:/opt/intel/daal/lib:/opt/intel/intelpython3/lib:/opt/intel/ipp/lib:/opt/intel/itac_2019/lib:/opt/intel/itac_latest/lib:/opt/intel/mkl/lib:/opt/intel/mkl_/lib:/opt/intel/mpirt/lib:/opt/intel/tbb/lib:/opt/intel/clck/2019.0/lib:/opt/intel/compilers_and_libraries_2019/linux/lib:/opt/intel/compilers_and_libraries/linux/lib:/opt/intel/itac/2019.0.018/lib:/opt/intel/itac_2019/intel64/lib:/opt/intel/itac_latest/intel64/lib:/opt/intel/parallel_studio_xe_2019.0.045/clck_2019/lib:/opt/intel/parallel_studio_xe_2019.0.045/itac_2019/lib:/opt/intel/parallel_studio_xe_2019/clck_2019/lib:/opt/intel/parallel_studio_xe_2019/itac_2019/lib\n",
      "2021-08-27 15:04:11.594410: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">desert-durian-59</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chrisxx/moleculenet\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chrisxx/moleculenet/runs/ty9uf1a2\" target=\"_blank\">https://wandb.ai/chrisxx/moleculenet/runs/ty9uf1a2</a><br/>\n",
       "                Run data is saved locally in <code>/home/chrisw/Documents/projects/2021/graph-transformer/notebooks/Pretraining/wandb/run-20210827_150410-ty9uf1a2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='moleculenet', entity='chrisxx')\n",
    "\n",
    "config = wandb.config\n",
    "config.n_atoms = 118\n",
    "config.n_bonds = 4\n",
    "config.emb_dim = 120\n",
    "config.nhead = 12\n",
    "config.nlayers = 6\n",
    "config.max_nodes = 400\n",
    "config.max_edges = 600\n",
    "config.max_nodes_data = 400\n",
    "config.max_edges_data = 600\n",
    "config.onlyRandom = True\n",
    "config.use_min = False # interestingly random seems to work better than using the minimal codes...\n",
    "config.dim_feedforward = 2048\n",
    "config.lr = 0.00003 # 10x smaller than the learning rate of the pretraining seems to be good\n",
    "config.clip_gradient = 0.5\n",
    "config.n_epochs = 25\n",
    "config.patience = 3\n",
    "config.factor = 0.95\n",
    "config.minimal_lr = 6e-8\n",
    "config.target_idx = 7\n",
    "config.batch_size = 64\n",
    "config.valid_patience = 5\n",
    "config.valid_minimal_improvement = 0.00\n",
    "config.pretrained_dir = '../../models/chembl/better_transformer/medium/leq1/'\n",
    "config.num_workers = 0\n",
    "config.load_last = True\n",
    "config.dataset = 'tox21' # supported 'bbbp', 'clintox', 'hiv', 'tox21'\n",
    "config.model_dir = '../../models/moleculenet/%s/'%config.dataset\n",
    "config.seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a388e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_descriptor', 'file_system'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiprocessing.get_all_sharing_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=1\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda = lambda T: [t.cuda() for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae3e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DFSCodeSeq2SeqFC(n_atoms=config.n_atoms,\n",
    "                         n_bonds=config.n_bonds, \n",
    "                         emb_dim=config.emb_dim, \n",
    "                         nhead=config.nhead, \n",
    "                         nlayers=config.nlayers, \n",
    "                         max_nodes=config.max_nodes, \n",
    "                         max_edges=config.max_edges,\n",
    "                         atom_encoder=nn.Embedding(config.n_atoms, config.emb_dim), \n",
    "                         bond_encoder=nn.Linear(config.n_bonds, config.emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ad67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_last:\n",
    "    model.load_state_dict(torch.load(config.pretrained_dir+'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6fa0145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFSCodeSeq2SeqFC(\n",
       "  (encoder): DFSCodeEncoder(\n",
       "    (emb_dfs): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (emb_seq): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (emb_atom): Embedding(118, 120)\n",
       "    (emb_bond): Linear(in_features=4, out_features=120, bias=True)\n",
       "    (mixer): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (enc): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_dfs_idx1): Linear(in_features=1200, out_features=400, bias=True)\n",
       "  (fc_dfs_idx2): Linear(in_features=1200, out_features=400, bias=True)\n",
       "  (fc_atom1): Linear(in_features=1200, out_features=118, bias=True)\n",
       "  (fc_atom2): Linear(in_features=1200, out_features=118, bias=True)\n",
       "  (fc_bond): Linear(in_features=1200, out_features=4, bias=True)\n",
       "  (fc_eos): Linear(in_features=1200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed501ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_scaffold_split(dataset):\n",
    "    splitter = dc.splits.ScaffoldSplitter()\n",
    "    shuffled = dataset.complete_shuffle()\n",
    "    trainidx, valididx, testidx = splitter.split(shuffled)\n",
    "    train = shuffled.select(trainidx)\n",
    "    valid = shuffled.select(valididx)\n",
    "    test = shuffled.select(testidx)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == 'clintox':\n",
    "    tasks, datasets, transformers = dc.molnet.load_clintox(reload=False, featurizer=dc.feat.RawFeaturizer(True))\n",
    "elif config.dataset == 'tox21':\n",
    "    tasks, datasets, transformers = dc.molnet.load_tox21(reload=False, featurizer=dc.feat.RawFeaturizer(True))\n",
    "elif config.dataset == 'hiv':\n",
    "    tasks, datasets, transformers = dc.molnet.load_hiv(reload=False, featurizer=dc.feat.RawFeaturizer(True))\n",
    "elif config.dataset == 'bbbp':\n",
    "    tasks, datasets, transformers = dc.molnet.load_bbbp(reload=False, featurizer=dc.feat.RawFeaturizer(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130deabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_head = nn.Linear(5*config.emb_dim, 1)\n",
    "model_head.to(device)\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13b0360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == 'tox21' or config.dataset == 'hiv' and not config.onlyRandom:\n",
    "    if config.dataset == 'tox21':\n",
    "        datadir = '../../datasets/moleculenet/tox21/srp53/'\n",
    "    if config.dataset == 'hiv':\n",
    "        datadir = '../../datasets/moleculenet/hiv_%d_%d/'%(config.max_nodes_data, config.max_edges_data)\n",
    "    collate_fn = collate_minc_rndc_y\n",
    "    trainloader = DataLoader(torch.load(datadir+'trainingset.pt'), batch_size=config.batch_size, shuffle=True, pin_memory=False, collate_fn=collate_fn)\n",
    "    validloader = DataLoader(torch.load(datadir+'validationset.pt'), batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn)\n",
    "    testloader = DataLoader(torch.load(datadir+'testset.pt'), batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn)\n",
    "else:\n",
    "    trainset, validset, testset = datasets\n",
    "    collate_fn = collate_minc_rndc_y\n",
    "    traindata = Deepchem2TorchGeometric(trainset, -1, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    validdata = Deepchem2TorchGeometric(validset, -1, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    testdata = Deepchem2TorchGeometric(testset, -1, onlyRandom=config.onlyRandom, max_nodes=config.max_nodes_data, max_edges=config.max_edges_data)\n",
    "    trainloader = DataLoader(traindata, batch_size=config.batch_size, shuffle=True, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    validloader = DataLoader(validdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)\n",
    "    testloader = DataLoader(testdata, batch_size=config.batch_size, shuffle=False, pin_memory=False, collate_fn=collate_fn, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cee73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optimizers.Adam(list(model.parameters()) + list(model_head.parameters()), lr=config.lr)\n",
    "\n",
    "lr_scheduler = optimizers.lr_scheduler.ReduceLROnPlateau(optim, mode='min', verbose=True, patience=config.patience, factor=config.factor)\n",
    "early_stopping_model = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                              path=config.model_dir+'checkpoint_model.pt')\n",
    "early_stopping_head = EarlyStopping(patience=config.valid_patience, delta=config.valid_minimal_improvement,\n",
    "                              path=config.model_dir+'checkpoint_head.pt')\n",
    "bce = torch.nn.BCEWithLogitsLoss()\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "158cd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def score(loader, model, model_head, use_min=False):\n",
    "    val_roc = 0\n",
    "    with torch.no_grad():\n",
    "        full_preds, target = [], []\n",
    "        for batch in tqdm.tqdm(loader):\n",
    "            rndc, minc, z, eattr, y = batch\n",
    "            if use_min:\n",
    "                code = to_cuda(minc)\n",
    "            else:\n",
    "                code = to_cuda(rndc)\n",
    "            y = y.to(device)\n",
    "            self_attn, features, eos = model.encode(code, to_cuda(z), to_cuda(eattr)) # not clear whether to use minc or randc\n",
    "            pred = sigmoid(model_head(features)).squeeze()\n",
    "            \n",
    "            pred_np = pred.detach().cpu().numpy().tolist()\n",
    "            y_np = y.detach().cpu().numpy().tolist()\n",
    "            full_preds += pred_np\n",
    "            target += y_np\n",
    "\n",
    "        target = np.asarray(target)\n",
    "        full_preds = np.asarray(full_preds)\n",
    "        roc = roc_auc_score(target, full_preds)\n",
    "        prc = average_precision_score(target, full_preds)\n",
    "    return roc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df794b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: CE 0.235655: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:19<00:00,  5.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC 0.6785499058380415 PRCAUC 0.1621307968006746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: CE 0.160989: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:20<00:00,  4.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC 0.6825235404896423 PRCAUC 0.2031881728697478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: CE 0.153207: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:20<00:00,  4.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC 0.698738229755179 PRCAUC 0.22505614178647249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: CE 0.142772: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:20<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "EarlyStopping counter: 1 out of 5\n",
      "ROCAUC 0.6798116760828625 PRCAUC 0.20193549747378425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: CE 0.135216:  36%|██████████████████████████████████████████████████████▎                                                                                                 | 35/98 [00:07<00:13,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard interrupt caught\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "try:\n",
    "    for epoch in range(config.n_epochs):  \n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for i, data in enumerate(pbar):\n",
    "            optim.zero_grad()\n",
    "            rndc, minc, z, eattr, y = data\n",
    "            if config.use_min:\n",
    "                code = to_cuda(minc)\n",
    "            else:\n",
    "                code = to_cuda(rndc)\n",
    "            z = to_cuda(z)\n",
    "            eattr = to_cuda(eattr)\n",
    "            y = y.to(device)\n",
    "            #prediction\n",
    "            self_attn, features, eos = model.encode(code, z, eattr)\n",
    "            prediction = model_head(features).squeeze()\n",
    "            loss = bce(prediction, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            if config.clip_gradient is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip_gradient)\n",
    "            optim.step()\n",
    "            epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "            \n",
    "            wandb.log({'loss':epoch_loss})\n",
    "            pbar.set_description('Epoch %d: CE %2.6f'%(epoch+1, epoch_loss))\n",
    "        model.eval()\n",
    "        roc_auc_valid, prc_auc_valid = score(validloader, model, model_head, config.use_min) \n",
    "        valid_scores += [roc_auc_valid]\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        early_stopping_model(-roc_auc_valid, model)\n",
    "        early_stopping_head(-roc_auc_valid, model_head)\n",
    "        curr_lr = list(optim.param_groups)[0]['lr']\n",
    "        wandb.log({'roc_valid':roc_auc_valid, 'prc_valid':prc_auc_valid, 'learning rate':curr_lr})\n",
    "        print('ROCAUC',roc_auc_valid, 'PRCAUC', prc_auc_valid)\n",
    "\n",
    "        if early_stopping_model.early_stop:\n",
    "            break\n",
    "\n",
    "        if curr_lr < config.minimal_lr:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model.state_dict(), config.model_dir+'_keyboardinterrupt.pt')\n",
    "    print('keyboard interrupt caught')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 11/13 [00:01<00:00,  8.44it/s]"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.model_dir+'checkpoint_model.pt'))\n",
    "model_head.load_state_dict(torch.load(config.model_dir+'checkpoint_head.pt'))\n",
    "model.eval()\n",
    "roc_auc_valid, prc_auc_valid = score(testloader, model, model_head) \n",
    "wandb.log({'roc_test':roc_auc_valid, 'prc_test':prc_auc_valid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69962626",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, prc = score(testloader, model, model_head, True)\n",
    "wandb.log({'roc_test_min':roc, 'prc_test_min':prc})\n",
    "print('ROC, PRC VALID', score(validloader, model, model_head, True))\n",
    "print('ROC, PRC TEST', score(testloader, model, model_head, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d30e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_roc = 0\n",
    "avg_prc = 0\n",
    "for i in range(20):\n",
    "    roc, prc = score(testloader, model, model_head, False)\n",
    "    avg_roc += roc\n",
    "    avg_prc += prc\n",
    "avg_roc /= 20\n",
    "avg_prc /= 20 \n",
    "wandb.log({'roc_test_avg20':avg_roc, 'prc_test_avg20':avg_prc})\n",
    "print('ROC, PRC TEST', avg_roc, avg_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d00c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

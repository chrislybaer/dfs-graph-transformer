{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e53e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 34 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3a058a1e994a1c8b65b4b4ac077f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from rdkit import Chem\n",
    "from dfs_transformer.utils import DFSCode2Graph, Graph2Mol, isValid, Smiles2DFSCode, DFSCode2Smiles, isValidMoleculeDFSCode\n",
    "from dfs_transformer.utils import load_selfattn_wandb, load_selfattn_local\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dfs_transformer as dfs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876ae4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/28 18:22:31\tERROR\twandb.jupyter\tFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meth-compiler-opters\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">legendary-violet-242</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dfstransformer/pubchem_newdataloader\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem_newdataloader</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dfstransformer/pubchem_newdataloader/runs/2mzcaoiu\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem_newdataloader/runs/2mzcaoiu</a><br/>\n",
       "                Run data is saved locally in <code>../../wandb/wandb/run-20221028_182231-2mzcaoiu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact r2r-nofeat:latest, 98.80MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 46882<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>../../wandb/wandb/run-20221028_182231-2mzcaoiu/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>../../wandb/wandb/run-20221028_182231-2mzcaoiu/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">legendary-violet-242</strong>: <a href=\"https://wandb.ai/dfstransformer/pubchem_newdataloader/runs/2mzcaoiu\" target=\"_blank\">https://wandb.ai/dfstransformer/pubchem_newdataloader/runs/2mzcaoiu</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model = \"r2r-nofeat\"\n",
    "if os.path.isdir(\"../../wandb/artifacts/%s\"%pretrained_model):\n",
    "    bert, cfg = load_selfattn_local(\"../../wandb/artifacts/%s\"%pretrained_model)\n",
    "else:\n",
    "    bert, cfg = load_selfattn_wandb(pretrained_model, wandb_dir=\"../../wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d301cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFSCodeSeq2SeqFC(\n",
       "  (encoder): DFSCodeEncoder(\n",
       "    (emb_dfs): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (emb_seq): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (emb_atom): Linear(in_features=118, out_features=120, bias=True)\n",
       "    (emb_bond): Linear(in_features=5, out_features=120, bias=True)\n",
       "    (mixer): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (enc): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=600, out_features=600, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=600, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=600, bias=True)\n",
       "          (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fcs): ModuleDict(\n",
       "    (dfs_from): Linear(in_features=1200, out_features=250, bias=True)\n",
       "    (dfs_to): Linear(in_features=1200, out_features=250, bias=True)\n",
       "    (atomic_num_from): Linear(in_features=1200, out_features=101, bias=True)\n",
       "    (atomic_num_to): Linear(in_features=1200, out_features=101, bias=True)\n",
       "    (formal_charge_from): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (formal_charge_to): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (chiral_tag_from): Linear(in_features=1200, out_features=5, bias=True)\n",
       "    (chiral_tag_to): Linear(in_features=1200, out_features=5, bias=True)\n",
       "    (num_Hs_from): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (num_Hs_to): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (hybridization_from): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (hybridization_to): Linear(in_features=1200, out_features=6, bias=True)\n",
       "    (is_aromatic_from): Linear(in_features=1200, out_features=2, bias=True)\n",
       "    (is_aromatic_to): Linear(in_features=1200, out_features=2, bias=True)\n",
       "    (bond_type): Linear(in_features=1200, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0ee16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = 1*['CN=C=O'] + 5*['Cc1cn2c(CN(C)C(=O)c3ccc(F)cc3C)c(C)nc2s1'] + 5*['Cc1cc(F)ccc1C(=O)N(C)Cc1c(C)nc2scc(C)n12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865b25bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrisw/Documents/projects/2023/graph-transformer/notebooks/generative_modelling/../../src/dfs_transformer/datasets/utils.py:300: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  x = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs],\n"
     ]
    }
   ],
   "source": [
    "dlist = []\n",
    "for smiles in smiles_list:\n",
    "    data = dfs.smiles2graph(smiles)\n",
    "    data.edge_features = data.edge_attr\n",
    "    data.node_features = nn.functional.one_hot(data.z-1, num_classes=118).float()\n",
    "    dlist += [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaf82ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "argmax(): Expected reduction dim 2 to have non-zero size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46831/950334796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rnd2rnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/2023/graph-transformer/notebooks/generative_modelling/../../src/dfs_transformer/training/utils.py\u001b[0m in \u001b[0;36mcollate_BERT\u001b[0;34m(dlist, mode, fraction_missing, use_loops, window)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mdfs_codes_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_codes_to_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mdfs_codes_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_codes_to_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mdfs_codes_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeaturizedDFSCodes2Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_codes_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"properties\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/2023/graph-transformer/notebooks/generative_modelling/../../src/dfs_transformer/utils/rdkit.py\u001b[0m in \u001b[0;36mFeaturizedDFSCodes2Dict\u001b[0;34m(dfs_code, missing_value, padding_value)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mdfs1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dfs_from\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mdfs2_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dfs_to\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0matm1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparseChempropAtomFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"atm_from\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0matm2_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparseChempropAtomFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"atm_to\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mbnd_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparseChempropBondFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bnd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/2023/graph-transformer/notebooks/generative_modelling/../../src/dfs_transformer/utils/rdkit.py\u001b[0m in \u001b[0;36mparseChempropAtomFeatures\u001b[0;34m(features, true_values, missing_value, padding_value)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mmask_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmissing_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoptions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mATOM_FEATURES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATOM_FEATURES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: argmax(): Expected reduction dim 2 to have non-zero size."
     ]
    }
   ],
   "source": [
    "inputs, outputs = dfs.collate_BERT(dlist, mode=\"rnd2rnd\", fraction_missing=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a560bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = bert.fwd_code(inputs)\n",
    "valid_list = []\n",
    "mols = []\n",
    "for smiles, code in zip(smiles_list, code_list):\n",
    "    try:\n",
    "        valid_list += [isValidMoleculeDFSCode(code)]\n",
    "        if valid_list[-1]:\n",
    "            print('input :', smiles)\n",
    "            print('output:', DFSCode2Smiles(code))\n",
    "            mols += [Chem.MolFromSmiles(smiles)]\n",
    "            mols += [Chem.MolFromSmiles(DFSCode2Smiles(code))]\n",
    "    except:\n",
    "        valid_list += [False]\n",
    "valid = np.asarray(valid_list)\n",
    "print(valid.sum()/len(valid))\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = bert.fwd_code_all(inputs)\n",
    "valid_list = []\n",
    "mols = []\n",
    "for smiles, code in zip(smiles_list, code_list):\n",
    "    try:\n",
    "        valid_list += [isValidMoleculeDFSCode(code)]\n",
    "        if valid_list[-1]:\n",
    "            print('input :', smiles)\n",
    "            print('output:', DFSCode2Smiles(code))\n",
    "            mols += [Chem.MolFromSmiles(smiles)]\n",
    "            mols += [Chem.MolFromSmiles(DFSCode2Smiles(code))]\n",
    "    except:\n",
    "        valid_list += [False]\n",
    "valid = np.asarray(valid_list)\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc763828",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['atm_from'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'dfs_from': torch.ones(25, 10, dtype=torch.long)*(-1),\n",
    "          'dfs_to': torch.ones(25, 10, dtype=torch.long)*(-1),\n",
    "          'atm_from': torch.ones(25, 10, 118)*(-1),\n",
    "          'atm_to':torch.ones(25, 10, 118)*(-1),\n",
    "          'bnd':torch.ones(25, 10, 5)*(-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e51a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['dfs_from'][0] = 0\n",
    "inputs['dfs_to'][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.fwd_code_all(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83624d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47742de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
